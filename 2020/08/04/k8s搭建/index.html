<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><meta name="keywords" content="[object Object]"><meta name="description" content="k8s搭建生产环境都是二进制安装（预编译安装）
12k8s官网地址https:&amp;#x2F"><meta name="author" content="zhi666"><title>kubernetes搭建 - 逸尘秀</title><meta description="k8s搭建生产环境都是二进制安装（预编译安装） 12k8s官网地址https:&amp;#x2F;&amp;#x2F;kubernetes.io&amp;#x2F;docs&amp;#x2F;tasks&amp;#x2F;tools&amp;#x2F;install-kubectl&amp;#x2F;"><meta property="og:type" content="article"><meta property="og:title" content="kubernetes搭建"><meta property="og:url" content="https://yc6.cool/2020/08/04/k8s%E6%90%AD%E5%BB%BA/"><meta property="og:site_name" content="逸尘秀"><meta property="og:description" content="k8s搭建生产环境都是二进制安装（预编译安装） 12k8s官网地址https:&amp;#x2F;&amp;#x2F;kubernetes.io&amp;#x2F;docs&amp;#x2F;tasks&amp;#x2F;tools&amp;#x2F;install-kubectl&amp;#x2F;"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2020-08-04T03:20:36.000Z"><meta property="article:modified_time" content="2023-11-01T02:25:44.563Z"><meta property="article:author" content="zhi666"><meta property="article:tag" content="docker"><meta property="article:tag" content="k8s"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://yc6.cool/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yc6.cool/2020/08/04/k8s%E6%90%AD%E5%BB%BA/"},"headline":"kubernetes搭建","image":["https://yc6.cool/img/avatar.png"],"datePublished":"2020-08-04T03:20:36.000Z","dateModified":"2023-11-01T02:25:44.563Z","author":{"@type":"Person","name":"zhi666"},"description":"k8s搭建生产环境都是二进制安装（预编译安装） 12k8s官网地址https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;tasks&#x2F;tools&#x2F;install-kubectl&#x2F;"}</script><link rel="alternative" href="/atom.xml" title="逸尘秀" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.12/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><link rel="stylesheet" href="/css/style.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><link rel="stylesheet" href="/live2d/waifu.css"><script type="text/javascript" async src="/live2d/autoload.js"></script></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="逸尘秀" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/media">影音</a><a class="navbar-item" href="/album">相册</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/self-talking">碎碎念</a><a class="navbar-item" href="/message">留言</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zhi666"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2020-08-04  <a class="commentCountImg" href="/2020/08/04/k8s%E6%90%AD%E5%BB%BA/#comment-container"><span class="display-none-class">3f2c59f5d7e2a9b0575f30bfefb528db</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="3f2c59f5d7e2a9b0575f30bfefb528db">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 小时  <i class="fas fa-pencil-alt"> </i>14.5 k</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">kubernetes搭建</h1><div class="content"><h1 id="k8s搭建"><a href="#k8s搭建" class="headerlink" title="k8s搭建"></a>k8s搭建</h1><p>生产环境都是二进制安装（预编译安装）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k8s官网地址</span><br><span class="line">https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;tasks&#x2F;tools&#x2F;install-kubectl&#x2F;</span><br></pre></td></tr></table></figure>

<a id="more"></a>


<p>yum无法自定义安装 </p>
<p>编译安装可以自定义安装 </p>
<p>预编译介于两者之间</p>
<p>准备三台服务器： </p>
<p>1、一台master </p>
<p>配置： IP：192.168.224.10 ，2H2G </p>
<p>2、两台node </p>
<p>配置： IP：192.168.224.11，192.168.224.12 ， 1H2G</p>
<h3 id="一、系统规划"><a href="#一、系统规划" class="headerlink" title="一、系统规划"></a><strong>一、系统规划</strong></h3><table>
<thead>
<tr>
<th>主机名</th>
<th>IP</th>
<th>组件</th>
</tr>
</thead>
<tbody><tr>
<td>k8smaster</td>
<td>192.168.224.10</td>
<td>etcd、kube-apiserver、kube-controller-manager、kube-scheduler</td>
</tr>
<tr>
<td>k8snode1</td>
<td>192.168.224.11</td>
<td>kubelet、kube-proxy、docker、dns、calico</td>
</tr>
<tr>
<td>k8snode2</td>
<td>192.168.224.12</td>
<td>kubelet、kube-proxy、docker、dns、calico</td>
</tr>
</tbody></table>
<h3 id="二、初始化系统基础环境"><a href="#二、初始化系统基础环境" class="headerlink" title="二、初始化系统基础环境"></a><strong>二、初始化系统基础环境</strong></h3><p>系统初始化时由于3台机器大部分操作都相同，我这里在配置过程中，在一台主机上进行配置文件创建，然后使用ansible进行分发，当然你也可以直接在对应主机上进行操作。</p>
<p><strong>1.设置主机名</strong></p>
<p><strong>在三台机器分别执行对应设置主机名的命令</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname --static k8smaster</span><br><span class="line">hostnamectl set-hostname --static k8snode1</span><br><span class="line">hostnamectl set-hostname --static k8snode2</span><br></pre></td></tr></table></figure>

<p><strong>2.配置免密钥登陆</strong></p>
<p><strong>以k8smaster为主机，对另外3台机器进行免密钥登陆</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen ##一路回车进行公钥私钥创建</span><br><span class="line">ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub -p 22  root@192.168.224.10</span><br><span class="line">ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub -p 22  root@192.168.224.11</span><br><span class="line">ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub  -p 22  root@192.168.224.12</span><br></pre></td></tr></table></figure>

<p><strong>3.安装ansible(可以不安装，把生成文件或者命令在各节点执行即可)</strong></p>
<p>这里只需在master节点安装即可，后续一些操作均在此机器上执行，然后把生成的文件分发至对应节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8smaster ~]# yum install -y epel-release</span><br><span class="line">[root@k8smaster ~]#  yum install ansible -y</span><br><span class="line">[root@k8smaster ~]# ansible --version</span><br></pre></td></tr></table></figure>

<p><strong>定义主机组</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;ansible&#x2F;hosts</span><br></pre></td></tr></table></figure>

<p><strong>[k8smaster]  #master节点服务器组k8smaster会报警告</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[k8szhu]   #master服务器组 组名和下面的名字不要一样。</span><br><span class="line">k8smaster      ansible_host&#x3D;192.168.224.10 ansible_ssh_user&#x3D;root</span><br><span class="line">#别名                  ip                      用户</span><br><span class="line"></span><br><span class="line">[k8snode]      #node节点服务器组       </span><br><span class="line">k8snode1       ansible_host&#x3D;192.168.224.11 ansible_ssh_user&#x3D;root</span><br><span class="line">k8snode2       ansible_host&#x3D;192.168.224.12 ansible_ssh_user&#x3D;root</span><br><span class="line"></span><br><span class="line">[k8sall]       #k8s集群服务器组</span><br><span class="line">k8smaster      ansible_host&#x3D;192.168.224.10 ansible_ssh_user&#x3D;root</span><br><span class="line">k8snode1       ansible_host&#x3D;192.168.224.11 ansible_ssh_user&#x3D;root</span><br><span class="line">k8snode2       ansible_host&#x3D;192.168.224.12 ansible_ssh_user&#x3D;root</span><br></pre></td></tr></table></figure>

<p><strong>测试ansible通讯是否正常</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m ping  #测试ansible是否正常</span><br></pre></td></tr></table></figure>

<p><strong>4.关闭防火墙、selinux(3台机器都执行，我这里使用ansible)</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s_masker ~]# ansible k8sall -m shell -a &#39;systemctl stop firewalld&#39;</span><br><span class="line">[root@k8s_masker ~]# ansible k8sall -m shell -a &#39;systemctl disable firewalld&#39;</span><br><span class="line"></span><br><span class="line">下面关闭selinux 如果之前设置好了就不用了</span><br><span class="line">[root@k8s_masker ~]# ansible k8sall -m shell -a &#39;setenforce  0&#39;  </span><br><span class="line">[root@k8s_masker ~]# ansible k8sall -m replace -a &#39;path&#x3D;&#x2F;etc&#x2F;selinux&#x2F;config regexp&#x3D;&quot;SELINUX&#x3D;enforcing&quot; replace&#x3D;SELINUX&#x3D;disabled&#39;</span><br><span class="line">[root@k8s_masker ~]# ansible k8sall -m replace -a &#39;path&#x3D;&#x2F;etc&#x2F;sysconfig&#x2F;selinux regexp&#x3D;&quot;SELINUX&#x3D;enforcing&quot; replace&#x3D;SELINUX&#x3D;disabled&#39;</span><br></pre></td></tr></table></figure>

<p><strong>5.配置host主机域名解析</strong></p>
<p>vim /etc/hosts</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.224.10  k8smaster</span><br><span class="line">192.168.224.11  k8snode1</span><br><span class="line">192.168.224.12  k8snode2</span><br></pre></td></tr></table></figure>

<p>文件分发到各节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;hosts dest&#x3D;&#x2F;etc&#x2F;hosts&quot;</span><br></pre></td></tr></table></figure>

<p>关闭缓存</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m shell -a &#39;swapoff -a &#39;</span><br><span class="line"></span><br><span class="line">关闭swap分区(不关后面master初始化会失败)</span><br><span class="line">临时关闭：swapoff -a</span><br><span class="line">永久关闭：注释掉&#x2F;etc&#x2F;fstab文件中的swap行</span><br><span class="line"></span><br><span class="line">ansible k8sall -m shell -a &#39;free -h&#39;</span><br><span class="line"> (确认关闭缓存)</span><br></pre></td></tr></table></figure>

<p><strong>6.设置内核</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">将桥接的IPv4流量传递到iptables的链</span><br><span class="line">[root@k8smaster ~]# vim &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br></pre></td></tr></table></figure>

<p>文件分发</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf dest&#x3D;&#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf&quot;</span><br><span class="line"></span><br><span class="line">开机自动加载模块</span><br><span class="line">ansible k8sall -m shell -a &#39;modprobe br_netfilter&#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf&#39;</span><br></pre></td></tr></table></figure>

<p><strong>7.时间同步</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">设置时区。</span><br><span class="line">sudo timedatectl set-timezone &#39;Asia&#x2F;Shanghai&#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;sudo timedatectl set-timezone &quot;Asia&#x2F;Shanghai&quot;&#39;</span><br><span class="line"></span><br><span class="line">ansible k8sall -m yum -a &quot;name&#x3D;ntpdate  state&#x3D;latest&quot;</span><br><span class="line"></span><br><span class="line">ansible k8sall -m cron -a &quot;name&#x3D;&#39;k8s cluster crontab&#39; minute&#x3D;*&#x2F;30 hour&#x3D;* day&#x3D;* month&#x3D;* weekday&#x3D;* job&#x3D;&#39;ntpdate time7.aliyun.com &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1&#39;&quot;</span><br></pre></td></tr></table></figure>

<h3 id="三-安装docker"><a href="#三-安装docker" class="headerlink" title="三.安装docker"></a><strong>三.安装docker</strong></h3><p><strong>1.移除旧的版本</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-selinux \</span><br><span class="line">                  docker-engine-selinux \</span><br><span class="line">                  docker-engine</span><br><span class="line"></span><br><span class="line">ansible卸载其他节点的</span><br><span class="line">ansible k8sall -m shell -a &#39;sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine -y &#39;</span><br></pre></td></tr></table></figure>

<p><strong>2.安装一些必要的系统依赖工具</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"></span><br><span class="line">ansible k8sall -m shell -a &#39;yum install -y yum-utils device-mapper-persistent-data lvm2&#39;</span><br></pre></td></tr></table></figure>

<p><strong>3.添加软件源信息</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m shell -a &#39;yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo&#39;</span><br><span class="line"></span><br><span class="line">更新yum缓存</span><br><span class="line">ansible k8sall -m shell -a &#39;yum makecache fast&#39;</span><br><span class="line"></span><br><span class="line">列出docker软件版本信息</span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure>

<p><strong>4.安装docker的指定版本</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">看哪个版本和k8s没有冲突就安装哪个(我安装18.06的)</span><br><span class="line">ansible k8sall -m shell -a &#39;yum install -y docker-ce-18.06.1.ce-3.el7&#39;</span><br></pre></td></tr></table></figure>

<p><strong>5.支持端口转发</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m shell -a &#39;echo &quot;net.ipv4.ip_forward &#x3D; 1&quot; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf &#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;sysctl -p&#39;</span><br><span class="line"></span><br><span class="line">启动docker</span><br><span class="line">ansible k8sall -m shell -a &#39;systemctl enable docker &amp;&amp; systemctl start docker&#39;</span><br></pre></td></tr></table></figure>

<p><strong>6.docker命令tab自动补全</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m shell -a &#39;yum install -y bash-completion&#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;source &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;completions&#x2F;docker&#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;source &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;bash_completion&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">配置阿里源加速</span><br><span class="line">vim &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;b9pmyelo.mirror.aliyuncs.com&quot;],</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">文件分发</span><br><span class="line">ansible k8sall -m copy -a &quot;src&#x3D;&#x2F;etc&#x2F;docker&#x2F;daemon.json dest&#x3D;&#x2F;etc&#x2F;docker&#x2F;daemon.json&quot;</span><br><span class="line"></span><br><span class="line">ansible k8sall -m shell -a &#39;systemctl restart docker&#39;</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure>



<h3 id="四-部署Kubernetes"><a href="#四-部署Kubernetes" class="headerlink" title="四.部署Kubernetes"></a><strong>四.部署Kubernetes</strong></h3><h4 id="1-k8s的基础配置"><a href="#1-k8s的基础配置" class="headerlink" title="1.k8s的基础配置"></a>1.k8s的基础配置</h4><p><strong>1.配置k8s源</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim  &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo</span><br><span class="line"></span><br><span class="line">[kubernetes]</span><br><span class="line">name&#x3D;Kubernetes</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64&#x2F;</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;1</span><br><span class="line">repo_gpgcheck&#x3D;1</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpg</span><br></pre></td></tr></table></figure>

<p><strong>文件分发</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ansible k8sall -m copy -a &#39;src&#x3D;&#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo dest&#x3D;&#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo&#39;</span><br><span class="line"></span><br><span class="line">ansible k8sall -m shell -a &#39;yum makecache fast  -y &#39;</span><br></pre></td></tr></table></figure>

<p><strong>2.安装kubeadm，kubelet和kubectl</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">查看各自的版本号</span><br><span class="line">yum list --showduplicates |grep &#39;^kube&#39;</span><br><span class="line"></span><br><span class="line">由于版本更新频繁，这里指定版本号部署：</span><br><span class="line"> yum install -y kubelet-1.18.4 kubeadm-1.18.4 kubectl-1.18.4</span><br><span class="line"> </span><br><span class="line">ansible k8sall -m shell -a &#39; yum install -y kubelet-1.18.4 kubeadm-1.18.4 kubectl-1.18.4 &#39;</span><br></pre></td></tr></table></figure>

<p><strong>重新加载守护进程和启动docker kubelet</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ansible k8sall -m shell -a &#39;systemctl daemon-reload&#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;systemctl enable docker kubelet&#39;</span><br><span class="line">ansible k8sall -m shell -a &#39;systemctl restart docker kubelet&#39;</span><br></pre></td></tr></table></figure>

<p><strong>2.1.kubectl 命令tab键补全</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">yum install -y bash-completion</span><br><span class="line">source &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~&#x2F;.bashrc</span><br><span class="line"></span><br><span class="line">kubectl describe pod    ##可以使用了</span><br><span class="line">或者</span><br><span class="line">添加命令自动补全：</span><br><span class="line">yum install -y bash-completion</span><br><span class="line">vim ~&#x2F;.bashrc</span><br><span class="line">添加</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line"></span><br><span class="line">执行下</span><br><span class="line">source ~&#x2F;.bashrc</span><br></pre></td></tr></table></figure>



<p><strong>3.部署Kubernetes Master</strong></p>
<p><strong>在master主节点执行</strong></p>
<p><strong>先查看版本，然后初始化网络服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8smaster ~]# kubelet --version</span><br><span class="line">Kubernetes v1.18.4</span><br></pre></td></tr></table></figure>

<p><strong>1)开始初始化</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --apiserver-advertise-address&#x3D;192.168.224.10 --kubernetes-version&#x3D;v1.18.4 --pod-network-cidr&#x3D;10.244.0.0&#x2F;16</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--apiserver-advertise-address&#x3D;192.168.224.10       #master组件监听的api地址，这里写masterIP地址即可或者多网卡选择另一个IP地址</span><br><span class="line"></span><br><span class="line">#自定义镜像源防止超时，</span><br><span class="line">kubeadm init --apiserver-advertise-address&#x3D;192.168.224.10 --image-repository&#x3D;registry.aliyuncs.com&#x2F;google_containers --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 --kubernetes-version&#x3D;v1.18.4</span><br></pre></td></tr></table></figure>

<p><strong>按提示创建文件，需要记住两行重要信息</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.224.10:6443 --token 23ydjv.e7065vwoee1cr6xf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:9eab18f17699039d57a12fd1552a63b686f893562cae6447cbda862e09827175</span><br><span class="line">    </span><br><span class="line">kubeadm join 192.168.224.10:6443 --token mzm37i.f5hiuopkjty4l19j \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:2ad0382860c95928cd058740d7f76ee0a28eb8a4ab318edf8ac9a687d7e818d8</span><br></pre></td></tr></table></figure>

<p>以上为kubeadm初始化命令的输出信息，记录输出结果的最后2行。这2行为在集群成员上执行的命令，用于将成员加入集群中。 </p>
<p>配置常规用户如何使用kubectl访问集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">把&#x2F;etc&#x2F;kubernetes&#x2F;admin.conf 复制到当前登录用户下.&#x2F;kube&#x2F;config 文件中.并修改权限为当前用户</span><br><span class="line"></span><br><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure>

<p>初始化成功后docker container ls -a 会发现启动了10个容器</p>
<p><a href="https://imgchr.com/i/awctN4"><img src="https://s1.ax1x.com/2020/08/04/awctN4.png" alt="awctN4.png"></a></p>
<p>同时在/etc/kubernetes/目录 会自动生成相关配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">admin.conf  controller-manager.conf  kubelet.conf  manifests  pki  scheduler.conf</span><br></pre></td></tr></table></figure>



<p><strong>设置环境变量</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;export KUBECONFIG&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;admin.conf&quot; &gt;&gt; ~&#x2F;.bash_profile</span><br><span class="line"></span><br><span class="line">    source ~&#x2F;.bash_profile</span><br><span class="line"></span><br><span class="line">确认版本信息</span><br><span class="line">kubectl version</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这时候查看pod</span><br><span class="line"></span><br><span class="line">kubectl get pod -n kube-system -o wide</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awgZKx.png" alt="awgZKx.png"></p>
<p><strong>2)初始化失败解决办法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">自动删除相关文件和数据</span><br><span class="line">kubeadm reset  所有的都要执行。</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 或者手动删除相关文件和images</span><br><span class="line"> rm -rf &#x2F;etc&#x2F;kubernetes&#x2F;*.conf</span><br><span class="line"> rm -rf &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;*.yaml</span><br><span class="line"> docker ps -a |awk &#39;&#123;print $1&#125;&#39; |xargs docker rm -f</span><br><span class="line"> systemctl  stop kubelet</span><br><span class="line">再次初始化前需要执行清除etcd所有数据的操作</span><br></pre></td></tr></table></figure>





<p><strong>4.master安装Flannel</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;master&#x2F;Documentation&#x2F;kube-flannel.yml</span><br><span class="line"></span><br><span class="line">wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;master&#x2F;Documentation&#x2F;kube-flannel.yml  </span><br><span class="line">	</span><br><span class="line">#如果安装失败，原因：外网不可访问 尝试以下方法</span><br><span class="line"># 在https:&#x2F;&#x2F;www.ipaddress.com&#x2F;查询raw.githubusercontent.com的真实IP。</span><br><span class="line">sudo vim &#x2F;etc&#x2F;hosts</span><br><span class="line">185.199.108.133 raw.githubusercontent.com</span><br><span class="line"></span><br><span class="line">#开启IPVS，修改ConfigMap的kube-system&#x2F;kube-proxy中的模式为ipvs</span><br><span class="line">kubectl edit cm kube-proxy -n kube-system </span><br><span class="line">修改：mode: &quot;ipvs&quot;</span><br><span class="line"></span><br><span class="line">重启kube-proxy</span><br><span class="line">kubectl get pod -n kube-system | grep kube-proxy | awk &#39;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&#39;</span><br><span class="line"></span><br><span class="line">然后再次部署安装。</span><br></pre></td></tr></table></figure>

<p><strong>查看所有pod</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kube-system -o wide</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awgmqK.png" alt="awgmqK.png"></p>
<p><strong>查看节点</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node   </span><br><span class="line">目前就只有master的信息</span><br></pre></td></tr></table></figure>

<p><strong>5.加入node节点</strong></p>
<p><strong>！！！在集群成员节点执行！！！</strong></p>
<p>执行token命令，参考主节点上执行kubeadm init命令的输出结果。</p>
<p> 样例（注意不能复制，一定要复制主节点kubeadm init命令的输出结果的最后2行）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.224.10:6443 --token 23ydjv.e7065vwoee1cr6xf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:9eab18f17699039d57a12fd1552a63b686f893562cae6447cbda862e09827175</span><br></pre></td></tr></table></figure>

<p><strong>查看所有node节点加入是否成功</strong></p>
<p> 在所有node上执行docker ps 查看k8s组件是否已安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker ps </span><br><span class="line"></span><br><span class="line">共有4个</span><br><span class="line">k8s_kube-flannel与k8s_kube-proxy </span><br><span class="line"></span><br><span class="line">POD的 kube-proxy与kube-flannel</span><br></pre></td></tr></table></figure>



<p><strong>在master上操作</strong></p>
<p>确认所有节点都加入到集群中，注意：下面的命令在成员加入后要等一段时间才会生效。最快10秒</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awgKaD.png" alt="awgKaD.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n kube-system</span><br><span class="line"></span><br><span class="line">kubectl get pods -n kube-system -o wide 查看详细信息 有12个在运行，新加入了4个</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awglPH.png" alt="awglPH.png"></p>
<p>以上信息有k8snode1这个从节点的信息，flannel和proxy都有三个pod</p>
<p><strong>到这里，k8s通过kubeadm搭建集群成功</strong></p>
<h4 id="2-安装控制台仪表盘"><a href="#2-安装控制台仪表盘" class="headerlink" title="2.安装控制台仪表盘"></a>2.安装控制台仪表盘</h4><p><strong>1.部署官方的 Dashboard</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">官方文档是最重要的参考资料：https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;tasks&#x2F;access-application-cluster&#x2F;web-ui-dashboard&#x2F;</span><br></pre></td></tr></table></figure>



<p>！！！在主节点执行！！</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;dashboard&#x2F;v1.10.1&#x2F;src&#x2F;deploy&#x2F;recommended&#x2F;kubernetes-dashboard.yaml</span><br><span class="line"></span><br><span class="line">#最新版本</span><br><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;dashboard&#x2F;v2.7.0&#x2F;aio&#x2F;deploy&#x2F;recommended.yaml</span><br></pre></td></tr></table></figure>

<p><strong>1.修改yaml文件内容</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> vim   kubernetes-dashboard.yaml</span><br><span class="line">把112行的 kubernetes-dashboard 镜像地址修改成阿里云的 在国外可以不修改</span><br><span class="line">image: registry.aliyuncs.com&#x2F;google_container&#x2F;kubernetes-dashboard-amd64:v1.10.1</span><br><span class="line">#这个也行</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;kubernetes-dashboard-amd64:v1.8.3</span><br><span class="line">在158行新增</span><br><span class="line">type: NodePort</span><br><span class="line">nodePort: 32666</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awg8xI.png" alt="awg8xI.png"></p>
<p><strong>安装Dashboard</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>

<p>使用master节点ip地址+端口来访问，协议是https的</p>
<p>查看Dashboard端口信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl --namespace&#x3D;kube-system get service kubernetes-dashboard</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awgadS.png" alt="awgadS.png"></p>
<p>以我自己的服务器为访问对象，使用<code>https://192.168.224.10:32666</code> 即可访问</p>
<p>可以执行以下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl proxy --address&#x3D;&#39;0.0.0.0&#39;  --accept-hosts&#x3D;&#39;^*$&#39;</span><br></pre></td></tr></table></figure>

<p>这时候就可以通过其它主机访问dashboard了.(以上地址中localhost改为ip地址)</p>
<p>如果没有登陆,则会默认定向到登陆页面,可以使用config或者token方式登陆.我们这里使用token方式登陆.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;192.168.224.10:8001&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;https:kubernetes-dashboard:&#x2F;proxy&#x2F;#!&#x2F;login</span><br></pre></td></tr></table></figure>



<p><strong>2.如果访问出现被防火墙拦截</strong></p>
<p>vim /etc/systemd/system/multi-user.target.wants/docker.service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#在server字段中添加</span><br><span class="line">ExecStartPost&#x3D;&#x2F;sbin&#x2F;iptables -I FORWARD -s 0.0.0.0&#x2F;0 -j ACCEPT</span><br><span class="line">#重启docker服务</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl  restart docker</span><br></pre></td></tr></table></figure>

<p><strong>3.创建账号密码文件(这步可以忽略)</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> cat &lt;&lt;EOF &gt;  &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;basic_auth_file</span><br><span class="line">admin,admin,2</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>配置密码文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-apiserver.yaml</span><br><span class="line"></span><br><span class="line">新增一行信息</span><br><span class="line">- --basic_auth_file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;basic_auth_file</span><br><span class="line">--service-node-port-range&#x3D;2-65535   #这行表示端口映射范围，默认是(30000-32767)</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awgTQ1.png" alt="awgTQ1.png"></p>
<p>重新启动kubelet服务，使密码配置生效 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart kubelet</span><br><span class="line"></span><br><span class="line">实测新增上面的信息后，重启会出错</span><br></pre></td></tr></table></figure>



<p><strong>应用API服务器配置</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;etc&#x2F;kubernetes&#x2F;manifests</span><br><span class="line">[root@k8smaster manifests]# kubectl apply -f kube-apiserver.yaml</span><br></pre></td></tr></table></figure>

<p>配置Dashboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get clusterrole&#x2F;cluster-admin -o yaml</span><br><span class="line"></span><br><span class="line">kubectl create clusterrolebinding login-on-dashboard-with-cluster-admin --clusterrole&#x3D;cluster-admin --user&#x3D;admin</span><br><span class="line"></span><br><span class="line">kubectl get clusterrolebinding&#x2F;login-on-dashboard-with-cluster-admin -o yaml</span><br></pre></td></tr></table></figure>



<p><strong>4.登录web页面</strong></p>
<p>用火狐浏览器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;192.168.224.10:32666</span><br></pre></td></tr></table></figure>



<p>登陆方式分为俩种：</p>
<p>1.kubeconfig</p>
<p>2.token </p>
<p>在master上执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">创建一个dashboard管理用户</span><br><span class="line">kubectl create serviceaccount dashboard-admin -n kube-system</span><br><span class="line"></span><br><span class="line">绑定用户为集群管理用户</span><br><span class="line">kubectl create clusterrolebinding dashboard-admin --clusterrole&#x3D;cluster-admin --serviceaccount&#x3D;kube-system:dashboard-admin</span><br><span class="line"></span><br><span class="line">执行完以上操作后,由于管理用户的名称为dashboard-admin,生成的对应的secret的值则为dashboard-admin-token-随机字符串我的机器上完整名称为dashboard-admin-token-f99st</span><br><span class="line"></span><br><span class="line">kubectl get secret -n kube-system #查看token</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/aw2VYQ.png" alt="aw2VYQ.png"></p>
<p>查看token的具体信息</p>
<p>kubectl describe secret dashboard-admin-token-f99st -n kube-system</p>
<p><img src="https://s1.ax1x.com/2020/08/04/aw2ZWj.png" alt="aw2ZWj.png"></p>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep dashboard-admin | awk &#39;&#123;print $1&#125;&#39;)</span><br></pre></td></tr></table></figure>

<p><strong>开启<code>跳过</code>登陆</strong></p>
<p>根据使用的版本不同,可能有的版本包含<code>skip</code>按钮,有的则不包含,在1.10.1里面默认不再显然skip按钮,其实dashboard安装有很多坑,如果有读者按照以上设置仍然不能正常成功登陆,但是仍然想要体验dashboard,可以开启默认关闭的<code>skip</code>按钮,这样就可以进入到dashboard管理界面了.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">执行命令</span><br><span class="line"></span><br><span class="line">kubectl edit deploy -n&#x3D;kube-system kubernetes-dashboard</span><br><span class="line">在containers下面的args栏里输入</span><br><span class="line"></span><br><span class="line">- --enable-skip-login</span><br></pre></td></tr></table></figure>

<p>然后保存即可.刷新web页面,登陆界面就会多出一个skip按钮.</p>
<p><strong>2.部署kuboard</strong></p>
<p>网站文档地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;kuboard.cn&#x2F;install&#x2F;install-dashboard.html</span><br></pre></td></tr></table></figure>

<p>稳定版</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;kuboard.cn&#x2F;install-script&#x2F;kuboard.yaml</span><br><span class="line">kubectl apply -f https:&#x2F;&#x2F;kuboard.cn&#x2F;install-script&#x2F;kuboard.yaml</span><br><span class="line">kubectl apply -f https:&#x2F;&#x2F;addons.kuboard.cn&#x2F;metrics-server&#x2F;0.3.6&#x2F;metrics-server.yaml</span><br></pre></td></tr></table></figure>

<p>查看 Kuboard 运行状态：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -l k8s.kuboard.cn/name=kuboard -n kube-system</span><br></pre></td></tr></table></figure>



<p>输出结果如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                       READY   STATUS        RESTARTS   AGE</span><br><span class="line">kuboard-54c9c4f6cb-6lf88   1&#x2F;1     Running       0          45s</span><br></pre></td></tr></table></figure>





<h3 id="五-k8s常用命令集合"><a href="#五-k8s常用命令集合" class="headerlink" title="五.k8s常用命令集合"></a><strong>五.k8s常用命令集合</strong></h3><h4 id="1-创建资源和删除"><a href="#1-创建资源和删除" class="headerlink" title="1. 创建资源和删除"></a>1. 创建资源和删除</h4><p>一般创建资源会有两种方式：通过文件或者命令创建。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过文件创建一个Deployment</span></span><br><span class="line">kubectl create -f /path/to/deployment.yaml</span><br><span class="line">cat /path/to/deployment.yaml | kubectl create -f -</span><br><span class="line"><span class="comment"># 不过一般可能更常用下面的命令来创建资源</span></span><br><span class="line">kubectl apply -f /path/to/deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过kubectl命令直接创建</span></span><br><span class="line">kubectl run nginx_app --image=nginx:1.9.1 --replicas=3</span><br></pre></td></tr></table></figure>

<p>kubectl还提供了一些更新资源的命令，比如kubectl edit、kubectl patch和kubectl replace等。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl edit：相当于先用get去获取资源，然后进行更新，最后对更新后的资源进行apply</span></span><br><span class="line">kubectl edit deployment/nginx_app</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl patch：使用补丁修改、更新某个资源的字段，比如更新某个node</span></span><br><span class="line">kubectl patch node/node-0 -p <span class="string">'&#123;"spec":&#123;"unschedulable":true&#125;&#125;'</span></span><br><span class="line">kubectl patch -f node-0.json -p <span class="string">'&#123;"spec": &#123;"unschedulable": "true"&#125;&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl replace：使用配置文件来替换资源</span></span><br><span class="line">kubectl replace -f /path/to/new_nginx_app.yaml</span><br></pre></td></tr></table></figure>

<p> 删除资源</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete - 在 Pod 中的容器执行命令</span><br><span class="line"></span><br><span class="line">kubectl delete pod cali-2 -n calib</span><br><span class="line">批量删除namespace 是calib中 状态为Error的所有pod：kubectl get pods -n calib | grep Error | awk &#39;&#123;print $1&#125;&#39; | xargs kubectl delete pod -n calib（注意 “Error”，“Completed”状态得首字母都是大写哦）</span><br><span class="line"></span><br><span class="line">根据resource名或label删除resource。</span><br><span class="line"></span><br><span class="line">kubectl delete -f rc-nginx.yaml</span><br><span class="line"></span><br><span class="line">kubectl delete po rc-nginx-btv4j</span><br><span class="line">kubectl delete po -lapp&#x3D;nginx-2</span><br></pre></td></tr></table></figure>



<h4 id="2-查看资源"><a href="#2-查看资源" class="headerlink" title="2. 查看资源"></a>2. 查看资源</h4><p>获取不同种类资源的信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一般命令的格式会如下：</span></span><br><span class="line">kubectl get &lt;resource_type&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比如获取K8s集群下pod的信息</span></span><br><span class="line">kubectl get pod</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更加详细的信息</span></span><br><span class="line">kubectl get pod -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看kube-apiserver的详细信息</span></span><br><span class="line">kubectl get pods -n kube-system kube-apiserver -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定资源的信息，格式：kubectl get &lt;resource_type&gt;/&lt;resource_name&gt;，比如获取deployment nginx-deployment的信息</span></span><br><span class="line">kubectl get deployment/nginx-deployment -o wide  </span><br><span class="line"><span class="comment">#deployment表示部署， nginx-deployment表示部署的名字叫nginx-deployment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以对指定的资源进行格式化输出，比如输出格式为json、yaml等</span></span><br><span class="line">kubectl get deployment/nginx-deployment -o json</span><br><span class="line">kubectl get deployment/nginx-deployment -o yaml</span><br><span class="line"><span class="comment"># 还可以对输出结果进行自定义，比如对pod只输出容器名称和镜像名称</span></span><br><span class="line">kubectl get pods nginx-deployment-55d5bfd679-nlknm -o custom-columns=CONTAINER:.spec.containers[0].name,IMAGE:.spec.containers[0].image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取某个特定key的值还可以输入如下命令得到，此目录参照go template的用法，且命令结尾'\n'是为了输出结果换行</span></span><br><span class="line">kubectl get pod nginx-deployment-55d5bfd679-nlknm -o template --template=<span class="string">'&#123;&#123;(index spec.containers 0).name&#125;&#125;&#123;&#123;"\n"&#125;&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还有一些可选项可以对结果进行过滤，这儿就不一一列举了，如有兴趣，可参照kubectl get --help说明</span></span><br><span class="line"></span><br><span class="line">kubectl logs - 从 Pod 中的容器打印日志</span><br><span class="line">这个特殊一点哦，这个不用指定TYPE，因为kubeclt logs 默认就是pod类型，所以 kubectl  logs  pod 会报错，<span class="string">"Error from server (NotFound): pods "</span>pod<span class="string">" not found"</span></span><br><span class="line">kubectl logs nginx-deployment-55d5bfd679-txglw</span><br></pre></td></tr></table></figure>

<p><strong>2.1, describe方法</strong></p>
<p>describe类似于get，同样用于获取resource的相关信息。不同的是，get获得的是更详细的resource个性的详细信息，describe获得的是resource集群相关的信息。describe命令同get类似，但是describe不支持-o选项，对于同一类型resource，describe输出的信息格式，内容域相同。<br>注：如果发现是查询某个resource的信息，使用get命令能够获取更加详尽的信息。但是如果想要查询某个resource的状态，如某个pod并不是在running状态，这时需要获取更详尽的状态信息时，就应该使用describe命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe po nginx-deployment-55d5bfd679-nlknm</span><br><span class="line">查询整个nginx的详细信息</span><br><span class="line">kubectl describe po  nginx-deployment</span><br></pre></td></tr></table></figure>



<h4 id="3-部署命令集"><a href="#3-部署命令集" class="headerlink" title="3. 部署命令集"></a>3. 部署命令集</h4><p>部署命令包括资源的运行管理命令、扩容和缩容命令和自动扩缩容命令。</p>
<p><strong>3.1 rollout命令</strong></p>
<p>管理资源的运行，比如eployment、Daemonet、StatefulSet等资源。</p>
<ul>
<li>查看部署状态：比如更新deployment/nginx_app中容器的镜像后查看其更新的状态。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">set</span> image deployment/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line">kubectl rollout status deployment/nginx-deployment</span><br></pre></td></tr></table></figure>

<ul>
<li>资源的暂停及恢复：发出一次或多次更新前暂停一个 Deployment，然后再恢复它，这样就能在Deployment暂停期间进行多次修复工作，而不会发出不必要的 rollout。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暂停</span></span><br><span class="line">kubectl rollout pause deployment/nginx-deployment</span><br><span class="line"><span class="comment"># 完成所有的更新操作命令后进行恢复</span></span><br><span class="line">kubectl rollout resume deployment/nginx-deployment</span><br></pre></td></tr></table></figure>

<ul>
<li>回滚：如上对一个Deployment的image做了更新，但是如果遇到更新失败或误更新等情况时可以对其进行回滚。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回滚之前先查看历史版本信息</span></span><br><span class="line">kubectl rollout <span class="built_in">history</span> deployment/nginx-deployment</span><br><span class="line"><span class="comment"># 回滚</span></span><br><span class="line">kubectl rollout undo deployment/nginx-deployment</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然也可以指定版本号回滚至指定版本 </span></span><br><span class="line">kubectl rollout undo deployment/nginx-deployment --to-revision=&lt;version_index&gt;</span><br></pre></td></tr></table></figure>

<p><strong>3.2 scale命令</strong></p>
<p>对一个Deployment、RS、StatefulSet进行扩/缩容。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 扩容</span></span><br><span class="line">kubectl scale deployment/nginx-deployment --replicas=5</span><br><span class="line"><span class="comment"># 如果是缩容，把对应的副本数设置的比当前的副本数小即可</span></span><br><span class="line"><span class="comment"># 另外，还可以针对当前的副本数目做条件限制，比如当前副本数是5则进行缩容至副本数目为3</span></span><br><span class="line">kubectl scale --current-replicas=5 --replicas=3 deployment/nginx-deployment</span><br></pre></td></tr></table></figure>

<p><strong>3.3 autoscale命令</strong></p>
<p>通过创建一个autoscaler，可以自动选择和设置在K8s集群中Pod的数量。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于CPU的使用率创建3-10个pod</span></span><br><span class="line">kubectl autoscale deployment/nginx-deployment --min=3 --max=10 --cpu_percent=80</span><br></pre></td></tr></table></figure>

<p><strong>3.4replace更新替换资源</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">replace命令用于对已有资源进行更新、替换。如前面create中创建的nginx，当我们需要更新resource的一些属性的时候，如果修改副本数量，增加、修改label，更改image版本，修改端口等。都可以直接修改原yaml文件，然后执行replace命令。</span><br><span class="line">注：名字不能被更新。另外，如果是更新label，原有标签的pod将会与更新label后的rc断开联系，有新label的rc将会创建指定副本数的新的pod，但是默认并不会删除原来的pod。所以此时如果使用get po将会发现pod数翻倍，进一步check会发现原来的pod已经不会被新rc控制，此处只介绍命令不详谈此问题，好奇者可自行实验。</span><br><span class="line"></span><br><span class="line">kubectl replace -f deployment.yml</span><br><span class="line">加个参数--force 先删除后再部署</span><br><span class="line">kubectl replace --force -f deployment.yml</span><br></pre></td></tr></table></figure>



<h4 id="4-集群管理命令"><a href="#4-集群管理命令" class="headerlink" title="4. 集群管理命令"></a>4. 集群管理命令</h4><p><strong>4.1 cordon &amp; uncordon命令</strong></p>
<p>设置是否能够将pod调度到该节点上。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">先查看节点当前信息</span><br><span class="line">kubectl get pod -n kube-system -o wide</span><br><span class="line"><span class="comment"># 不可调度</span></span><br><span class="line">kubectl cordon k8snode1</span><br><span class="line">此时节点信息会发生变化</span><br><span class="line">NAME        STATUS                     ROLES    AGE    VERSION</span><br><span class="line">k8smaster   Ready                      master   140m   v1.18.4</span><br><span class="line">k8snode1    Ready,SchedulingDisabled   &lt;none&gt;   131m   v1.18.4</span><br><span class="line">k8snode2    Ready                      &lt;none&gt;   131m   v1.18.4</span><br><span class="line"><span class="comment">#看到k8snode1状态发了了变化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当某个节点需要维护时，可以驱逐该节点上的所有pods(会删除节点上的pod，并且自动通过上面命令设置</span></span><br><span class="line"><span class="comment"># 该节点不可调度，然后在其他可用节点重新启动pods)</span></span><br><span class="line">kubectl drain k8snode1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 待其维护完成后，可再设置该节点为可调度</span></span><br><span class="line">kubectl uncordon k8snode1</span><br><span class="line"><span class="comment">#这时候k8snode1状态恢复成Ready了</span></span><br></pre></td></tr></table></figure>

<p><strong>4.2 taint命令</strong></p>
<p>目前仅能作用于节点资源，一般这个命令通常会结合pod的tolerations字段结合使用，对于没有设置对应toleration的pod是不会调度到有该taint的节点上的，这样就可以避免pod被调度到不合适的节点上。一个节点的taint一般会包括key、value和effect(effect只能在NoSchedule, PreferNoSchedule, NoExecute中取值)。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置taint</span></span><br><span class="line">kubectl taint nodes k8snode1 key1=value1:NoSchedule</span><br><span class="line"><span class="comment"># 移除taint</span></span><br><span class="line">kubectl taint nodes k8snode1 key1:NoSchedule</span><br></pre></td></tr></table></figure>

<p>如果pod想要被调度到上述设置了taint的节点node-0上，则需要在该pod的spec的tolerations字段设置：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"key1"</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">"Equal"</span></span><br><span class="line">  <span class="attr">value:</span> <span class="string">"value1"</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"key1"</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">"Exists"</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure>

<h4 id="5-其它"><a href="#5-其它" class="headerlink" title="5. 其它"></a>5. 其它</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 映射端口允许外部访问</span></span><br><span class="line">kubectl expose deployment/nginx-deployment --<span class="built_in">type</span>=<span class="string">'NodePort'</span> --port=80</span><br><span class="line"><span class="comment"># 然后通过kubectl get services -o wide来查看被随机映射的端口我的是80:32118/TCP</span></span><br><span class="line"><span class="comment"># 如此就可以通过node的外部IP和端口来访问nginx服务了,</span></span><br><span class="line">http://192.168.224.12:32118/</span><br><span class="line"></span><br><span class="line"><span class="comment">#也可以手动指定svc的端口</span></span><br><span class="line">kubectl expose deployment nginx --name nginx-svc --protocol TCP --port 8000 --target-port 80 --<span class="built_in">type</span> NodePort</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转发本地端口访问Pod的应用服务程序</span></span><br><span class="line">kubectl port-forward nginx-deployment-89bc67794-6vsc7 8090:80</span><br><span class="line"><span class="comment"># 如此，本地可以访问：curl -i localhost:8090</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在创建或启动某些资源的时候没有达到预期结果，可以使用如下命令先简单进行故障定位</span></span><br><span class="line">kubectl describe deployment/nginx-deployment</span><br><span class="line">kubectl logs nginx-deployment-89bc67794-6vsc7</span><br><span class="line">kubectl <span class="built_in">exec</span> deployment/nginx-deployment -c nginx &lt;<span class="built_in">command</span>&gt;</span><br><span class="line"></span><br><span class="line">kubectl <span class="built_in">exec</span> deployment/nginx-deployment ls /etc/nginx</span><br><span class="line"><span class="comment"># 集群内部调用接口(比如用curl命令)，可以采用代理的方式，根据返回的ip及端口作为baseurl</span></span><br><span class="line">kubectl proxy &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看K8s支持的完整资源列表</span></span><br><span class="line">kubectl api-resources</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看K8s支持的api版本</span></span><br><span class="line">kubectl api-versions</span><br></pre></td></tr></table></figure>

<h1 id="部署管理k8s"><a href="#部署管理k8s" class="headerlink" title="部署管理k8s"></a><strong>部署管理k8s</strong></h1><h3 id="一-k8s部署第一个pod应用"><a href="#一-k8s部署第一个pod应用" class="headerlink" title="一.k8s部署第一个pod应用"></a><strong>一.k8s部署第一个pod应用</strong></h3><p><strong>Pod的状态描述</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">状态值        描述</span><br><span class="line">Pending      API Server已经创建该Pod，但在Pod内还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程。</span><br><span class="line">Runnung      Pod内所有容器均已创建，且至少有一个容器处于运行状态、正在启动状态或正在重启状态。</span><br><span class="line">Succeeded    Pod内所有容器均成功执行后退出，且不会再重启。</span><br><span class="line">Failed       Pod内所有容器均已退出，但至少有一个容器退出为失败状态。</span><br><span class="line">Unknown      由于某种原因无法获取该Pod的状态，可能由于网络通信不畅导致。</span><br></pre></td></tr></table></figure>

<h4 id="1-编写一个pod-yaml文件"><a href="#1-编写一个pod-yaml文件" class="headerlink" title="1.编写一个pod.yaml文件"></a>1.编写一个pod.yaml文件</h4><p>查看yaml编写文档每个字段的意思</p>
<p><code>kubectl explain deployment.spec</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kube100-site</span><br><span class="line">  labels:</span><br><span class="line">    app: web</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: front-end</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">      - containerPort: 80</span><br><span class="line">    - name: flaskapp-demo</span><br><span class="line">      image: jcdemo&#x2F;flaskapp</span><br><span class="line">      ports:</span><br><span class="line">      - containerPort: 5000</span><br></pre></td></tr></table></figure>

<p>然后通过命令创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f pod.yaml</span><br><span class="line"></span><br><span class="line">pod &quot;kube100-site&quot; created</span><br></pre></td></tr></table></figure>

<p>然后我们就可以使用我们前面比较熟悉的 kubectl 命令来查看 POD 的状态了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -o wide </span><br><span class="line"></span><br><span class="line">查看到了ip 可以分别访问80端口和5000端口</span><br><span class="line">curl  -i 10.244.2.17</span><br><span class="line">curl  -i 10.244.2.17:5000</span><br></pre></td></tr></table></figure>

<p>如果有问题也可以删除</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f pod.yaml</span><br></pre></td></tr></table></figure>



<h4 id="2-API部署例子"><a href="#2-API部署例子" class="headerlink" title="2.API部署例子"></a>2.API部署例子</h4><p>我们使用kubectl run来运行我们的第一个应用 ，run命令用于新建一个部署。我们需要提供部署名称和应用镜像地址（DockerHub以外的镜像需要全路径）作为参数。通过–port参数，还可以指定app使用的端口。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">kubectl run kubernetes-bootcamp --image&#x3D;docker.io&#x2F;jocatalin&#x2F;kubernetes-bootcamp:v1 --port&#x3D;8080</span><br><span class="line"></span><br><span class="line">具体后台的操作包括：</span><br><span class="line">查找适合这个应用运行的node</span><br><span class="line">调度这个应用在选定的node上运行</span><br><span class="line">配置集群，在需要的时候为这个应用调配新的node</span><br></pre></td></tr></table></figure>

<p>查看应用部署情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployments</span><br><span class="line"></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure>

<p><strong>查看应用</strong><br>在Kubernetes中，pod运行于私有的、隔离的网络。默认情况下，Pod对集群内的其他pod和服务是可见的，但对网络外部是不可见的。我们在使用kubectl时，实际上是通过API端点(endpoint)（可以理解为URL）与应用进行交互。<br>通过kubectl proxy可以创建一个代理，让你能与集群内的私有网络进行通讯。代理运行过程中没有任何输出，按Ctrl+C可以关闭代理程序。<br>重新打开一个终端运行代理程序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl proxy</span><br></pre></td></tr></table></figure>

<p>这样就建立了一条从本地主机到集群的连接，代理程序允许从终端直接访问API。通过代理端点，你可以查看所有的API，端点地址是：<code>http://localhost:8001</code>。你可以通过curl命令直接查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;localhost:8001&#x2F;version</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">API服务器自动为每个pod建立同名的API端点，而且这些端点可以通过代理访问。</span><br><span class="line">首先获取Pod名称存储到POD_NAME中：</span><br><span class="line">$ export POD_NAME&#x3D;$(kubectl get pods -o go-template --template &#39;&#123;&#123;range .items&#125;&#125;&#123;&#123;.metadata.name&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&#39;)</span><br><span class="line">$ echo Name of the Pod: $POD_NAME</span><br><span class="line">Name of the Pod: kubernetes-bootcamp-390780338-x81xj</span><br><span class="line"> </span><br><span class="line">然后向pod中运行的应用发送一个http请求，这个url就指向了Pod的API。</span><br><span class="line">$ curl http:&#x2F;&#x2F;localhost:8001&#x2F;api&#x2F;v1&#x2F;proxy&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;kubernetes-bootcamp-5d7f968ccb-n5vqb&#x2F;</span><br><span class="line">Hello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-390780338-x81xj | v&#x3D;1</span><br><span class="line">注意：命令行中的参数“kubernetes-bootcamp-5d7f968ccb-dtdv5”，要从“echo POD_NAME”中获得。</span><br></pre></td></tr></table></figure>





<h3 id="二-k8s部署RC和RS应用"><a href="#二-k8s部署RC和RS应用" class="headerlink" title="二.k8s部署RC和RS应用"></a><strong>二.k8s部署RC和RS应用</strong></h3><p><strong>Replication Controller</strong></p>
<p><code>RC</code>是定义一个期望的场景，声明某种<code>Pod</code>的副本数量在任意时刻都符合某个预期值，所以<code>RC</code>的定义包括如下几个部分：<br> <code>Pod</code>期待的副本数量。<br> 用于筛选目标<code>Pod</code>的<code>Label Selector</code>。<br> 当<code>Pod</code>的副本数量小于预期数量时，用于创建新<code>Pod</code>的<code>Pod</code>模板（<code>templete</code>）。</p>
<p>Replication Controller简称RC，RC是Kubernetes系统中的核心概念之一，简单来说，RC可以保证在任意时间运行Pod的副本数量，能够保证Pod总是可用的。如果实际Pod数量比指定的多那就结束掉多余的，如果实际数量比指定的少就新启动一些Pod，当Pod失败、被删除或者挂掉后，RC都会去自动创建新的Pod来保证副本数量，所以即使只有一个Pod，我们也应该使用RC来管理我们的Pod。</p>
<p>现在我们来使用RC来管理我们前面使用的Nginx的Pod，YAML文件如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: rc-demo</span><br><span class="line">  labels:</span><br><span class="line">    name: rc</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:                  #可选</span><br><span class="line">    name: rc</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">     labels:</span><br><span class="line">       name: rc</span><br><span class="line">    spec:</span><br><span class="line">     containers:</span><br><span class="line">     - name: nginx-demo</span><br><span class="line">       image: nginx</span><br><span class="line">       ports:</span><br><span class="line">       - containerPort: 80</span><br></pre></td></tr></table></figure>

<p>上面的YAML文件相对于我们之前的Pod的格式：<br> kind：ReplicationController<br> spec.replicas: 指定Pod副本数量，默认为1<br> spec.selector: RC通过该属性来筛选要控制的Pod<br> spec.template: 这里就是我们之前的Pod的定义的模块，但是不需要apiVersion和kind了<br> spec.template.metadata.labels: 注意这里的Pod的labels要和spec.selector相同，这样RC就可以来控制当前这个Pod了。<br> 这个YAML文件中的意思就是定义了一个RC资源对象，它的名字叫rc-demo，保证一直会有3个Pod运行，Pod的镜像是nginx镜像。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">注意spec.selector和spec.template.metadata.labels这两个字段必须相同，否则会创建失败的，当然我们也可以不写spec.selector，这样就默认与Pod模板中的metadata.labels相同了。</span><br><span class="line">然后我们来创建上面的RC对象(保存为 rc-demo.yaml):</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f rc-demo.yaml</span><br><span class="line"> 查看RC：</span><br><span class="line">kubectl get rc</span><br><span class="line"></span><br><span class="line">查看具体信息：</span><br><span class="line">kubectl describe rc rc-demo</span><br><span class="line"></span><br><span class="line">然后我们通过RC来修改下Pod的副本数量为2：</span><br><span class="line">kubectl apply -f rc-demo.yaml</span><br><span class="line">或者</span><br><span class="line">kubectl edit rc rc-demo</span><br><span class="line"></span><br><span class="line">最新的k8s貌似已经不支持rolling-update命令了</span><br><span class="line">而且我们还可以用RC来进行滚动升级，比如我们将镜像地址更改为nginx:1.7.9:</span><br><span class="line">kubectl rolling-update rc-demo --image&#x3D;nginx:1.7.9</span><br><span class="line">但是如果我们的Pod中多个容器的话，就需要通过修改YAML文件来进行修改了:</span><br><span class="line">kubectl rolling-update rc-demo -f rc-demo.yaml</span><br><span class="line">如果升级完成后出现了新的问题，想要一键回滚到上一个版本的话，使用RC只能用同样的方法把镜像地址替换成之前的，然后重新滚动升级。</span><br></pre></td></tr></table></figure>

<p><strong>Replication Set（RS）</strong></p>
<blockquote>
<p><strong>Replication</strong> Set简称RS，随着Kubernetes的高速发展，官方已经推荐我们使用RS和Deployment来代替RC了，实际上RS和RC的功能基本一致，目前唯一的一个区别就是RC只支持基于等式的selector（env=dev或environment!=qa），但RS还支持基于集合的selector（version in (v1.0, v2.0)），这对复杂的运维管理就非常方便了。</p>
</blockquote>
<p>kubectl命令行工具中关于RC的大部分命令同样适用于我们的RS资源对象。不过我们也很少会去单独使用RS，它主要被Deployment这个更加高层的资源对象使用，除非用户需要自定义升级功能或根本不需要升级Pod，在一般情况下，我们推荐使用Deployment而不直接使用Replica Set。</p>
<p><strong>最后总结下关于RC/RS的一些特性和作用吧：</strong></p>
<p>大部分情况下，我们可以通过定义一个RC实现的Pod的创建和副本数量的控制<br> RC中包含一个完整的Pod定义模块（不包含apiversion和kind）<br> RC是通过label selector机制来实现对Pod副本的控制的<br> 通过改变RC里面的Pod副本数量，可以实现Pod的扩缩容功能<br> 通过改变RC里面的Pod模板中镜像版本，可以实现Pod的滚动升级功能（但是不支持一键回滚，需要用相同的方法去修改镜像地址）</p>
<h3 id="三-k8s部署deployment和SVC"><a href="#三-k8s部署deployment和SVC" class="headerlink" title="三.k8s部署deployment和SVC"></a><strong>三.k8s部署deployment和SVC</strong></h3><h4 id="1-Deployment"><a href="#1-Deployment" class="headerlink" title="1.Deployment"></a>1.Deployment</h4><p>Deployment同样也是Kubernetes系统的一个核心概念，主要职责和RC一样的都是保证Pod的数量和健康，二者大部分功能都是完全一致的，我们可以看成是一个升级版的RC控制器，那Deployment又具备那些新特性呢？</p>
<p>RC的全部功能：Deployment具备RC的全部功能<br> 事件和状态查看：可以查看Deployment的升级详细进度和状态<br> 回滚：当升级Pod的时候如果出现问题，可以使用回滚操作回滚到之前的任一版本<br> 版本记录：每一次对Deployment的操作，都能够保存下来，这也是保证可以回滚到任一版本的基础<br> 暂停和启动：对于每一次升级都能够随时暂停和启动</p>
<p>作为对比，我们知道Deployment作为新一代的RC，不仅在功能上更为丰富了，同时我们也说过现在官方也都是推荐使用Deployment来管理Pod的，比如一些官方组件kube-dns、kube-proxy也都是使用的Deployment来管理的，所以当大家在使用的使用也最好使用Deployment来管理Pod。</p>
<p>可以看出一个Deployment拥有多个Replica Set，而一个Replica Set拥有一个或多个Pod。一个Deployment控制多个RS主要是为了支持回滚机制，每当Deployment操作时，Kubernetes会重新生成一个Replica Set并保留，以后有需要的话就可以回滚至之前的状态。<br> 下面创建一个Deployment，它创建了一个Replica Set来启动3个nginx pod，yaml文件如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>

<p>这里需要注意:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1 </span><br><span class="line">kind: Deployment</span><br></pre></td></tr></table></figure>

<p>此部署版本已被弃用，并且在k8s的最新版本（例如1.16）中不再可用。</p>
<p>现在，您必须指定<code>apiVersion: apps/v1</code>并略微修改模板（需要selector.matchLabels字段）。并且与Pod模板中的metadata.labels相同</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deploy</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:       #新增这个字段</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx    #名字和下面的pod模板的labels名相同</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx    #和这里的相同</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>



<p>将上面内容保存为: nginx-deployment.yaml，执行命令:</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nginx-deployment.yaml</span><br><span class="line">deployment <span class="string">"nginx-deploy"</span> created</span><br><span class="line"></span><br><span class="line">查看deployment</span><br><span class="line">$ kubectl get deployments</span><br></pre></td></tr></table></figure>

<p>可以看到Deployment已经创建了1个Replica Set了，执行下面的命令查看rs和pod:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get rs</span><br><span class="line"></span><br><span class="line">$ kubectl get pod --show-labels</span><br></pre></td></tr></table></figure>

<p>上面的Deployment的yaml文件中的replicas:3将会保证我们始终有3个POD在运行</p>
<p><strong>下面是通过Deployment部署的</strong></p>
<p><strong>方法一：通过控制台部署。</strong></p>
<p>部署Nginx到 K8S集群中：<br>进入 控制台-&gt; 工作负载-&gt; 点击链接“➕创建”位于网页左上角 。复制如下代码来从云服务器自动下载nginx镜像。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1 # for versions before 1.9.0 use apps&#x2F;v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  replicas: 2 # tells deployment to run 2 pods matching the template</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>

<p><strong>方法二：通过命令行部署</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 将内容保存为 yml文件。</span><br><span class="line">2. 执行命令：kubectl create -f deployment.yml --save-config</span><br></pre></td></tr></table></figure>

<p>在Nginx部署完成后，在Master执行下面的命令，确保docker有部署到集群上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -o wide </span><br><span class="line"></span><br><span class="line">可以内部访问</span><br><span class="line">curl -I 10.244.1.3</span><br><span class="line"></span><br><span class="line">通过leber查看pod的详细情况</span><br><span class="line">kubectl get pods -o wide -l app&#x3D;nginx</span><br><span class="line"></span><br><span class="line">删除应用</span><br><span class="line">kubectl delete pods -l app&#x3D;nginx </span><br><span class="line">这里删除后马上又会开启两个.</span><br><span class="line">kubectl delete pods nginx-deployment-5bf87f5f59-8vbtk</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/aw2QmV.png" alt="aw2QmV.png"></p>
<p>查看应用部署情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployments </span><br><span class="line"></span><br><span class="line">查看节点IP</span><br><span class="line">kubectl get svc</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将Docker中的虚拟机暴露在网络中</span><br><span class="line">kubectl expose deployment nginx-deployment --type&#x3D;&quot;LoadBalancer&quot;</span><br></pre></td></tr></table></figure>

<p>查看Docker镜像在主节点的映射端口。本例中：镜像为80端口，映射到主节点的32118端口上。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get services</span><br></pre></td></tr></table></figure>

<p>查看资源的详细信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pods nginx</span><br></pre></td></tr></table></figure>



<h4 id="2-Service"><a href="#2-Service" class="headerlink" title="2.Service"></a>2.Service</h4><p>Service是一种抽象的对象，它定义了一组Pod的逻辑集合和一个用于访问它们的策略，一个Serivce下面包含的Pod集合一般是由<strong>Label Selector</strong>来决定的。假如我们后端运行了3个副本，这些副本都是可以替代的，因为前端并不关心它们使用的是哪一个后端服务。尽管由于各种原因后端的Pod集合会发生变化，但是前端却不需要知道这些变化，也不需要自己用一个列表来记录这些后端的服务，Service的这种抽象就可以帮我们达到这种解耦的目的。</p>
<p>三种ip</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Node IP：Node节点的IP地址</span><br><span class="line">Pod IP：Pod的IP地址</span><br><span class="line">Cluster IP：Service的IP地址</span><br></pre></td></tr></table></figure>

<p>首先，Node IP是Kubernetes集群中节点的物理网卡IP地址(一般为内网)，所有属于这个网络的服务器之间都可以直接通信，所以Kubernetes集群外要想访问Kubernetes集群内部的某个节点或者服务，肯定得通过Node IP进行通信（这个时候一般是通过外网IP了）</p>
<p>然后Pod IP是每个Pod的IP地址，它是Docker Engine根据docker0网桥的IP地址段进行分配的（我们这里使用的是flannel这种网络插件保证所有节点的Pod IP不会冲突）</p>
<p>最后Cluster IP是一个虚拟的IP，仅仅作用于Kubernetes Service这个对象，由Kubernetes自己来进行管理和分配地址，当然我们也<strong>无法ping这个地址</strong>，他没有一个真正的实体对象来响应，他只能结合Service Port来组成一个可以通信的服务。</p>
<p><strong>定义Service</strong></p>
<p>定义Service的方式和各种资源对象的方式类型一样，假定我们有一组Pod服务，它们对外暴露了 80 端口，同时都被打上了app=myapp这样的标签，那么我们就可以像下面这样来定义一个Service对象：<br> pod示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: test</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: myapp</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: myapp</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>

<p>service基于pod的示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: myservice</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: myapp</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 80</span><br></pre></td></tr></table></figure>

<p>然后通过的使用kubectl create -f myservice.yaml就可以创建一个名为myservice的Service对象，它会将请求代理到使用 TCP 端口为 80，具有标签app=myapp的Pod上，这个Service会被系统分配一个我们上面说的Cluster IP，该Service还会持续的监听selector下面的Pod，会把这些Pod信息更新到一个名为myservice的Endpoints对象上去，这个对象就类似于我们上面说的Pod集合了。<br> 需要注意的是，Service能够将一个接收端口映射到任意的targetPort。 默认情况下，targetPort将被设置为与port字段相同的值。 可能更有趣的是，targetPort 可以是一个字符串，引用了 backend Pod 的一个端口的名称。 因实际指派给该端口名称的端口号，在每个 backend Pod 中可能并不相同，所以对于部署和设计 Service ，这种方式会提供更大的灵活性。<br> <strong>另外Service能够支持 TCP 和 UDP 协议，默认是 TCP 协议。</strong></p>
<p><strong>kube-proxy</strong></p>
<p>在<code>Kubernetes</code>集群中，每个<code>Node</code>会运行一个<code>kube-proxy</code>进程, 负责为<code>Service</code>实现一种 VIP（虚拟 IP，就是我们上面说的<code>clusterIP</code>）的代理形式，现在的<code>Kubernetes</code>中默认是使用的<code>iptables</code>这种模式来代理。这种模式，<code>kube-proxy</code>会监视<code>Kubernetes master</code>对 Service 对象和 Endpoints 对象的添加和移除。 对每个 Service，它会添加上 iptables 规则，从而捕获到达该 Service 的 clusterIP（虚拟 IP）和端口的请求，进而将请求重定向到 Service 的一组 backend 中的某一个个上面。 对于每个 Endpoints 对象，它也会安装 iptables 规则，这个规则会选择一个 backend Pod。</p>
<p>默认的策略是，随机选择一个 backend。 我们也可以实现基于客户端 IP 的会话亲和性，可以将 <code>service.spec.sessionAffinity</code> 的值设置为 “ClientIP” （默认值为 “None”）。</p>
<p>另外需要了解的是如果最开始选择的 Pod 没有响应，iptables 代理能够自动地重试另一个 Pod，所以它需要依赖 readiness probes。</p>
<p><strong>Service 类型</strong></p>
<p>在定义Service的时候可以指定一个自己需要的类型的Service，如果不指定的话默认是ClusterIP类型。</p>
<p>可以使用的服务类型如下：</p>
<p>1、<code>ClusterIP</code>：通过集群的内部 IP 暴露服务，选择该值，服务只能够在集群内部可以访问，这也是默认的ServiceType。<br> 2、<code>NodePort</code>：通过每个 Node 节点上的 IP 和静态端口（NodePort）暴露服务。NodePort 服务会路由到 ClusterIP 服务，这个 ClusterIP 服务会自动创建。通过请求 :，可以从集群的外部访问一个 NodePort 服务。<br> 3、<code>LoadBalancer</code>：使用云提供商的负载局衡器，可以向外部暴露服务。外部的负载均衡器可以路由到 NodePort 服务和 ClusterIP 服务，这个需要结合具体的云厂商进行操作。<br> 4、<code>ExternalName</code>：通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容（例如， foo.bar.example.com）。没有任何类型代理被创建，这只有 Kubernetes 1.7 或更高版本的 kube-dns 才支持。</p>
<p><strong>NodePort 类型</strong></p>
<p>如果设置 type 的值为 “NodePort”，Kubernetes master 将从给定的配置范围内（默认：30000-32767）分配端口，每个 Node 将从该端口（每个 Node 上的同一端口）代理到 Service。该端口将通过 Service 的 spec.ports[*].nodePort 字段被指定，如果不指定的话会自动生成一个端口。</p>
<p>需要注意的是，Service 将能够通过 :spec.ports[].nodePort 和 spec.clusterIp:spec.ports[].port 而对外可见。</p>
<p>接下来创建一个NodePort的服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: myservice</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: myapp</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">    name: myapp-http</span><br><span class="line">    nodePort: 32560</span><br></pre></td></tr></table></figure>



<p>创建该Service:</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f service-demo.yaml</span><br><span class="line"></span><br><span class="line">注意上面有创建myservice服务的需要删掉</span><br></pre></td></tr></table></figure>

<p>然后我们可以查看Service对象信息：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="keyword">get</span> svc</span><br><span class="line"><span class="type">NAME</span>               <span class="type">TYPE</span>        <span class="type">CLUSTER</span>-<span class="type">IP</span>       <span class="type">EXTERNAL</span>-<span class="type">IP</span>   <span class="type">PORT</span>(<span class="type">S</span>)          <span class="type">AGE</span></span><br><span class="line">kubernetes         <span class="type">ClusterIP</span>   <span class="number">10.96</span>.<span class="number">0.1</span>        &lt;<span class="keyword">none</span>&gt;        <span class="number">443</span>/<span class="type">TCP</span>          22h</span><br><span class="line">myservice          <span class="type">NodePort</span>    <span class="number">10.100</span>.<span class="number">114.118</span>   &lt;<span class="keyword">none</span>&gt;        <span class="number">80</span>:<span class="number">32560</span>/<span class="type">TCP</span>     8s</span><br></pre></td></tr></table></figure>

<p>可以看到myservice的 TYPE 类型已经变成了NodePort，后面的PORT(S)部分也多了一个 32560 的随机映射端口。</p>
<p><strong>ExternalName</strong></p>
<p>ExternalName 是 Service 的特例，它没有 selector，也没有定义任何的端口和 Endpoint。 对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kind</span>: <span class="selector-tag">Service</span></span><br><span class="line"><span class="selector-tag">apiVersion</span>: <span class="selector-tag">v1</span></span><br><span class="line"><span class="selector-tag">metadata</span>:</span><br><span class="line">  <span class="selector-tag">name</span>: <span class="selector-tag">my-service</span></span><br><span class="line">  <span class="selector-tag">namespace</span>: <span class="selector-tag">prod</span></span><br><span class="line"><span class="selector-tag">spec</span>:</span><br><span class="line">  <span class="selector-tag">type</span>: <span class="selector-tag">ExternalName</span></span><br><span class="line">  <span class="selector-tag">externalName</span>: <span class="selector-tag">my</span><span class="selector-class">.database</span><span class="selector-class">.example</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure>

<p>当查询主机 my-service.prod.svc.cluster.local 时，集群的 DNS 服务将返回一个值为 my.database.example.com 的 CNAME 记录。 访问这个服务的工作方式与其它的相同，唯一不同的是重定向发生在 DNS 层，而且不会进行代理或转发。 如果后续决定要将数据库迁移到 Kubernetes 集群中，可以启动对应的 Pod，增加合适的 Selector 或 Endpoint，修改 Service 的 type，完全不需要修改调用的代码，这样就完全解耦了。</p>
<h4 id="3-1-网站服务应用"><a href="#3-1-网站服务应用" class="headerlink" title="3.1.网站服务应用"></a>3.1.网站服务应用</h4><p>在控制台中创建</p>
<p>应用一</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: result</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - name: &quot;result-service&quot;</span><br><span class="line">      port: 5001</span><br><span class="line">      targetPort: 80</span><br><span class="line">      nodePort: 31001</span><br><span class="line">  selector:</span><br><span class="line">    app: result</span><br></pre></td></tr></table></figure>

<p>应用二</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: result</span><br><span class="line">  namespace: default</span><br><span class="line">  labels:</span><br><span class="line">    env: test</span><br><span class="line">    app: result</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: result</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: result-pod</span><br><span class="line">      labels:</span><br><span class="line">        app: result</span><br><span class="line">        env: test</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: dockersamples&#x2F;examplevotingapp_result:before</span><br><span class="line">        name: result</span><br></pre></td></tr></table></figure>

<p>查看是否运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure>





<h3 id="四-k8s部署PV的应用"><a href="#四-k8s部署PV的应用" class="headerlink" title="四.k8s部署PV的应用"></a><strong>四.k8s部署PV的应用</strong></h3><p><strong>概念</strong></p>
<p>PV 的全称是：PersistentVolume（持久化卷），是对底层的共享存储的一种抽象，PV 由管理员进行创建和配置，它和具体的底层的共享存储技术的实现方式有关，比如 Ceph、GlusterFS、NFS 等，都是通过插件机制完成与共享存储的对接。</p>
<h4 id="NFS方式"><a href="#NFS方式" class="headerlink" title="NFS方式"></a>NFS方式</h4><p>1、关闭防火墙</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop firewalld.service</span><br><span class="line">$ systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<p>2、安装配置 nfs</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum -y install nfs-utils rpcbind</span><br></pre></td></tr></table></figure>

<p>3、共享目录设置权限：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> mkdir /<span class="keyword">data</span>/k8s -p</span><br><span class="line">$ chmod <span class="number">755</span> /<span class="keyword">data</span>/k8s/</span><br></pre></td></tr></table></figure>

<p>4、配置 nfs，nfs 的默认配置文件在 /etc/exports 文件下，在该文件中添加下面的配置信息：</p>
<figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/exports</span><br><span class="line">/data/k8s  *(rw,<span class="keyword">sync</span>,no_root_squash)</span><br></pre></td></tr></table></figure>

<p>5、配置说明：<br> /data/k8s：是共享的数据目录<br> *：表示任何人都有权限连接，当然也可以是一个网段，一个 IP，也可以是域名<br> rw：读写的权限<br> sync：表示文件同时写入硬盘和内存<br> no_root_squash：当登录 NFS 主机使用共享目录的使用者是 root 时，其权限将被转换成为匿名使用者，通常它的 UID 与 GID，都会变成 nobody 身份</p>
<p>启动服务 nfs 需要向 rpc 注册，rpc 一旦重启了，注册的文件都会丢失，向他注册的服务都需要重启<br> 注意启动顺序，先启动 rpcbind</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> systemctl start rpcbind.service</span><br><span class="line"> systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line"> </span><br><span class="line"> systemctl status rpcbind</span><br><span class="line">状态信息是正在运行的</span><br></pre></td></tr></table></figure>

<p>看到上面的 Started 证明启动成功了。</p>
<p>然后启动 nfs 服务：</p>
<figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nfs.service</span><br><span class="line">systemctl enable nfs</span><br><span class="line">systemctl status nfs</span><br></pre></td></tr></table></figure>

<p>同样看到 Started 则证明 NFS Server 启动成功了。</p>
<p>另外还可以通过下面的命令确认下：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ rpcinfo -p<span class="params">|grep nfs</span></span><br><span class="line"><span class="params">	100003    3   tcp   2049  nfs</span></span><br><span class="line"><span class="params">    100003    4   tcp   2049  nfs</span></span><br><span class="line"><span class="params">    100227    3   tcp   2049  nfs_acl</span></span><br><span class="line"><span class="params">    100003    3   udp   2049  nfs</span></span><br><span class="line"><span class="params">    100003    4   udp   2049  nfs</span></span><br><span class="line"><span class="params">    100227    3   udp   2049  nfs_acl</span></span><br></pre></td></tr></table></figure>

<p>查看具体目录挂载权限：</p>
<figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /<span class="keyword">var</span>/lib/nfs/etab</span><br><span class="line">/data/k8s    *(rw,<span class="keyword">sync</span>,wdelay,<span class="keyword">hide</span>,nocrossmnt,secure,no_root_squash,no_all_squash,no_subtree_check,secure_locks,acl,no_pnfs,anonuid=<span class="number">65534</span>,anongid=<span class="number">65534</span>,sec=sys,secure,no_root_squash,no_all_squash)</span><br></pre></td></tr></table></figure>

<p>到这里nfs server就安装成功了，接下来我们在节点192.168.224.11和12上来安装 nfs 的客户端来验证下 nfs</p>
<p>安装 nfs 当前也需要先关闭防火墙：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<p>然后安装 nfs</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install nfs-utils rpcbind</span><br></pre></td></tr></table></figure>

<p>安装完成后，和上面的方法一样，先启动 rpc、然后启动 nfs：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start rpcbind.service </span><br><span class="line">systemctl enable rpcbind.service </span><br><span class="line">systemctl start nfs.service    </span><br><span class="line">systemctl enable nfs.service</span><br></pre></td></tr></table></figure>

<p>挂载数据目录 客户端启动完成后，我们在客户端来挂载下 nfs 测试下：<br> 首先检查下 nfs 是否有共享目录：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">showmount -e <span class="number">192.168</span>.<span class="number">224.10</span></span><br><span class="line"></span><br><span class="line">Export list <span class="keyword">for</span> <span class="number">192.168</span>.<span class="number">224.10</span><span class="symbol">:</span></span><br><span class="line">/data/k8s *</span><br></pre></td></tr></table></figure>

<p>然后我们在客户端上新建目录：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /<span class="keyword">data</span></span><br></pre></td></tr></table></figure>

<p>将 nfs 共享目录挂载到上面的目录：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t nfs <span class="number">192.168</span>.<span class="number">224.10</span><span class="symbol">:/data/k8s</span> /data</span><br></pre></td></tr></table></figure>

<p>挂载成功后，在客户端上面的目录中新建一个文件，然后我们观察下 nfs 服务端的共享目录下面是否也会出现该文件：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ touch /<span class="keyword">data</span>/test.txt</span><br></pre></td></tr></table></figure>

<p>然后在 nfs 服务端查看：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ls -ls /<span class="keyword">data</span>/k8s/</span><br><span class="line">total <span class="number">4</span></span><br><span class="line"><span class="number">0</span> -rw-r--r-- <span class="number">1</span> root root <span class="number">0</span> <span class="number">6</span>月  <span class="number">24</span> <span class="number">02</span>:<span class="number">41</span> test.txt</span><br></pre></td></tr></table></figure>

<p>如果上面出现了 test.txt 的文件，那么证明我们的 nfs 挂载成功了。</p>
<h4 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h4><p>有了上面的 NFS 共享存储，下面我们就可以来使用 PV 和 PVC 了。PV 作为存储资源，主要包括存储能力、访问模式、存储类型、回收策略等关键信息，下面我们来新建一个 PV 对象，使用 nfs 类型的后端存储，1G 的存储空间，访问模式为 ReadWriteOnce，回收策略为 Recyle，对应的 YAML 文件如下：(pv1-demo.yaml)</p>
<figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name:  pv1</span><br><span class="line">spec:</span><br><span class="line">  capacity: </span><br><span class="line">    storage: <span class="number">1</span>Gi</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  nfs:</span><br><span class="line">    path: <span class="regexp">/data/</span>k8s</span><br><span class="line">    server: <span class="number">192.168</span><span class="number">.224</span><span class="number">.10</span></span><br></pre></td></tr></table></figure>

<p>Kubernetes 支持的 PV 类型有很多，比如常见的 Ceph、GlusterFs、NFS，甚至 HostPath也可以，不过 HostPath 仅仅可以用于单机测试，更多的支持类型可以前往 <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Kubernetes PV 官方文档</a>进行查看，因为每种存储类型都有各自的特点，所以我们在使用的时候可以去查看相应的文档来设置对应的参数。</p>
<p>然后同样的，直接使用 kubectl 创建即可：</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f pv1-demo.yaml</span><br><span class="line">persistentvolume <span class="string">"pv1"</span> created</span><br><span class="line">    </span><br><span class="line">$ kubectl get pv</span><br><span class="line">NAME   <span class="built_in">CAPACITY</span>   ACCESS MODES   RECLAIM POLICY   STATUS      <span class="built_in">CLAIM</span>   STORAGECLASS   REASON   AGE</span><br><span class="line">pv1    <span class="number">1</span>Gi        RWO            Recycle          Available</span><br></pre></td></tr></table></figure>

<p>我们可以看到 pv1 已经创建成功了，状态是 Available，表示 pv1 就绪，可以被 PVC 申请。我们来分别对上面的属性进行一些解读。</p>
<p><strong>capacity(存储能力)</strong></p>
<p>一般来说，一个 PV 对象都要指定一个存储能力，通过 PV 的 <strong>capacity</strong>属性来设置的，目前只支持存储空间的设置，就是我们这里的 storage=1Gi，不过未来可能会加入 IOPS、吞吐量等指标的配置。</p>
<p><strong>accessModes(访问模式)</strong></p>
<p>AccessModes 是用来对 PV 进行访问模式的设置，用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：</p>
<ul>
<li>ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载</li>
<li>ReadOnlyMany（ROX）：只读权限，可以被多个节点挂载</li>
<li>ReadWriteMany（RWX）：读写权限，可以被多个节点挂载</li>
</ul>
<blockquote>
<p>注意：一些 PV 可能支持多种访问模式，但是在挂载的时候只能使用一种访问模式，多种访问模式是不会生效的。</p>
</blockquote>
<p>下图是一些常用的 Volume 插件支持的访问模式：</p>
<p><img src="https://s1.ax1x.com/2020/08/04/awRAnx.png" alt="awRAnx.png"></p>
<p><strong>persistentVolumeReclaimPolicy(回收策略)</strong></p>
<p>我这里指定的 PV 的回收策略为 Recycle，目前 PV 支持的策略有三种：</p>
<ul>
<li>Retain（保留）- 保留数据，需要管理员手工清理数据</li>
<li>Recycle（回收）- 清除 PV 中的数据，效果相当于执行 rm -rf /thevoluem/*</li>
<li>Delete（删除）- 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务，比如 ASW EBS。</li>
</ul>
<p>不过需要注意的是，目前只有 NFS 和 HostPath 两种类型支持回收策略。当然一般来说还是设置为 Retain 这种策略保险一点。</p>
<p><strong>status（状态）</strong></p>
<p>一个 PV 的生命周期中，可能会处于4中不同的阶段：</p>
<ul>
<li>Available（可用）：表示可用状态，还未被任何 PVC 绑定</li>
<li>Bound（已绑定）：表示 PV 已经被 PVC 绑定</li>
<li>Released（已释放）：PVC 被删除，但是资源还未被集群重新声明</li>
<li>Failed（失败）： 表示该 PV 的自动回收失败</li>
</ul>
<h3 id="五-k8s部署PVC的应用"><a href="#五-k8s部署PVC的应用" class="headerlink" title="五.k8s部署PVC的应用"></a><strong>五.k8s部署PVC的应用</strong></h3><p><strong>概念</strong></p>
<p>PVC 的全称是：PersistentVolumeClaim（持久化卷声明），PVC 是用户存储的一种声明，PVC 和 Pod 比较类似，Pod 消耗的是节点，PVC 消耗的是 PV 资源，Pod 可以请求 CPU 和内存，而 PVC 可以请求特定的存储空间和访问模式。对于真正使用存储的用户不需要关心底层的存储实现细节，只需要直接使用 PVC 即可。</p>
<p><strong>准备工作</strong></p>
<p>在使用 PVC 之前，我们还得把其他节点上的 nfs 客户端给安装上，比如我们这里：</p>
<p><img src="https://s1.ax1x.com/2020/08/04/awREB6.png" alt="awREB6.png"></p>
<p>需要在所有节点安装 nfs 客户端程序，必须在所有节点都安装 nfs 客户端，否则可能会导致 PV 挂载不上的问题。<br>安装命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  nfs-utils rpcbind</span><br></pre></td></tr></table></figure>

<h4 id="新建-PVC"><a href="#新建-PVC" class="headerlink" title="新建 PVC"></a>新建 PVC</h4><p>同样的，我们来新建一个数据卷声明，来请求 1Gi 的存储容量，访问模式也是 ReadWriteOnce，YAML 文件如下：(pvc-nfs.yaml)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-nfs</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br></pre></td></tr></table></figure>

<p>可以看到这里的声明方法几乎和新建 PV 是一样的，在新建 PVC 之前，可以看下之前创建的 PV 的状态：</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pv</span><br><span class="line">NAME   <span class="built_in">CAPACITY</span>   ACCESS MODES   RECLAIM POLICY   STATUS      <span class="built_in">CLAIM</span>   STORAGECLASS   REASON   AGE</span><br><span class="line">pv1    <span class="number">1</span>Gi        RWO            Recycle          Available                                   <span class="number">22</span>m</span><br></pre></td></tr></table></figure>

<p>可以看到当前 pv1 是在 Available 的一个状态，所以这个时候 PVC 可以和这个 PV 进行绑定：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f pvc-nfs.yaml</span><br><span class="line">persistentvolumeclaim <span class="string">"pvc-nfs"</span> created</span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME      STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">pvc-nfs   Bound    pv1      <span class="number">1</span>Gi        RWO                           <span class="number">10</span>s</span><br></pre></td></tr></table></figure>

<p>可以看到 pvc-nfs 创建成功了，状态是 Bound 状态了，这个时候再看下 PV 的状态呢：</p>
<figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pv</span><br><span class="line">NAME   <span class="built_in">CAPACITY</span>   ACCESS MODES   RECLAIM POLICY   STATUS   <span class="built_in">CLAIM</span>             STORAGECLASS   REASON   AGE</span><br><span class="line">pv1    <span class="number">1</span>Gi        RWO            Recycle          Bound    <span class="keyword">default</span>/pvc-nfs                           <span class="number">24</span>m</span><br></pre></td></tr></table></figure>

<p>可以看到 PV 也是 Bound 状态了，对应的声明是 default/pvc-nfs，就是 default 命名空间下面的 pvc-nfs，证明刚刚新建的 pvc-nfs 和 pv-nfs 绑定成功了。</p>
<blockquote>
<p>提问：并没有在 pvc-nfs 中指定关于 pv 的什么标志，它们之间是怎么就关联起来了的呢？<br> 解答：其实这是系统自动帮我们去匹配的，它会根据我们的声明要求去查找处于 Available 状态的 PV，如果没有找到的话那么PVC 就会一直处于 Pending 状态，找到了的话当然就会把当前的 PVC 和目标 PV 进行绑定，这个时候状态就会变成 Bound 状态了。</p>
</blockquote>
<h4 id="使用-PVC"><a href="#使用-PVC" class="headerlink" title="使用 PVC"></a>使用 PVC</h4><p>使用之前的 nginx 的镜像来测试下：(nfs-pvc-deploy.yaml)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-pvc</span><br><span class="line">spec:</span><br><span class="line">  selector:       <span class="comment">#新增这个字段</span></span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-pvc</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-pvc</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: web</span><br><span class="line">        volumeMounts:                        <span class="comment">#挂载容器中的目录到pvc nfs中的目录</span></span><br><span class="line">        - name: www</span><br><span class="line">          mountPath: /usr/share/nginx/html</span><br><span class="line">      volumes:</span><br><span class="line">      - name: www</span><br><span class="line">        persistentVolumeClaim:              <span class="comment">#指定pvc</span></span><br><span class="line">          claimName: pvc-nfs</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-pvc</span><br><span class="line">  labels:</span><br><span class="line">    app: nfs-pvc</span><br><span class="line">spec:</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: web              <span class="comment">#容器端口或名字</span></span><br><span class="line">  selector:</span><br><span class="line">    app: nfs-pvc</span><br></pre></td></tr></table></figure>

<p>这里使用 nginx 镜像，将容器的 /usr/share/nginx/html 目录通过 volume 挂载到名为 pvc-nfs 的 PVC 上面，然后创建一个 NodePort 类型的 Service 来暴露服务：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nfs-pvc-deploy.yaml</span><br><span class="line">deployment.extensions <span class="string">"nfs-pvc"</span> created</span><br><span class="line">service <span class="string">"nfs-pvc"</span> created</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="keyword">get</span> pods</span><br><span class="line"><span class="type">NAME</span>                       <span class="type">READY</span>   <span class="type">STATUS</span>    <span class="type">RESTARTS</span>   <span class="type">AGE</span></span><br><span class="line">nfs-pvc-588c7b9b5d-h7r2s   <span class="number">1</span>/<span class="number">1</span>     <span class="type">Running</span>   <span class="number">0</span>          34s</span><br><span class="line">nfs-pvc-588c7b9b5d-hss56   <span class="number">1</span>/<span class="number">1</span>     <span class="type">Running</span>   <span class="number">0</span>          34s</span><br><span class="line">nfs-pvc-588c7b9b5d-k2t8z   <span class="number">1</span>/<span class="number">1</span>     <span class="type">Running</span>   <span class="number">0</span>          34s</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="keyword">get</span> svc</span><br><span class="line"><span class="type">AME</span>               <span class="type">TYPE</span>        <span class="type">CLUSTER</span>-<span class="type">IP</span>       <span class="type">EXTERNAL</span>-<span class="type">IP</span>   <span class="type">PORT</span>(<span class="type">S</span>)          <span class="type">AGE</span></span><br><span class="line">kubernetes         <span class="type">ClusterIP</span>   <span class="number">10.96</span>.<span class="number">0.1</span>        &lt;<span class="keyword">none</span>&gt;        <span class="number">443</span>/<span class="type">TCP</span>          25h</span><br><span class="line">nfs-pvc            <span class="type">NodePort</span>    <span class="number">10.99</span>.<span class="number">223.226</span>    &lt;<span class="keyword">none</span>&gt;        <span class="number">80</span>:<span class="number">30061</span>/<span class="type">TCP</span>     75s</span><br></pre></td></tr></table></figure>

<p>然后就可以通过任意节点的 IP:30061 端口来访问这里的 Nginx 服务了，但是这个时候访问会出现403，这是为什么？我们再去看看 nfs 共享数据目录下面有没有数据呢？</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /<span class="keyword">data</span>/k8s</span><br></pre></td></tr></table></figure>

<p>发现并没有任何数据，这是因为我们把容器目录/user/share/nginx/html和挂载到了pvc-nfs这个 PVC 上面，这个 PVC 就是对应着我们上面的 nfs 的共享数据目录的，该目录下面还没有任何数据，所以我们访问就出现了403，现在我们在/data/k8s这个目录下面新建一个 index.html 的文件：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> echo <span class="string">"&lt;h1&gt;Hello Kubernetes~&lt;/h1&gt;"</span> &gt;&gt; <span class="regexp">/data/k</span>8s/index.html</span><br><span class="line"> ls /data/k8s/</span><br><span class="line">index.html</span><br></pre></td></tr></table></figure>

<p>可以看到共享数据目录中已经有一个 index.html 的文件了，由于我们挂载了 pvc2-nfs 到上面的 nginx 容器中去，是不是这个时候容器目录**/user/share/nginx/html<strong>下面也有</strong>index.html**这个文件了啊？所以这个时候我们再来访问下服务，任一节点IP:30061</p>
<p><img src="https://s1.ax1x.com/2020/08/04/awRQgA.png" alt="awRQgA.png"></p>
<p>现在是不是正常了啊，但是我们可以看到我们容器中的数据是直接放到共享数据目录根目录下面的，如果以后有一个新的 nginx 容器也做了数据目录的挂载，会发生冲突，所以这个时候就不太好区分了，可以在 Pod 中使用一个新的属性：subPath，该属性可以来解决这个问题，只需要更改上面的 Pod 的 YAML 文件即可：</p>
<p><strong>创建pvc子目录</strong></p>
<figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">volumeMounts:</span><br><span class="line">- name: www</span><br><span class="line">  subPath: nginxpvc-test</span><br><span class="line">  mountPath: <span class="regexp">/usr/</span>share/nginx/html</span><br></pre></td></tr></table></figure>

<p>更改完 YAML 文件后，我们重新更新即可：</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">kubectl apply -f nfs-pvc-deploy.yaml</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/08/04/awR8DP.png" alt="awR8DP.png"></p>
<p>更新完后，我们再去看看 nfs 的数据共享目录：</p>
<p>这个时候是把nginxpvc-test这个目录映射到容器里的/usr/share/nginx/html/目录里了</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> ls /<span class="keyword">data</span>/k8s/</span><br><span class="line">index.html  nginxpvc-test</span><br><span class="line"></span><br><span class="line">ls /<span class="keyword">data</span>/k8s/nginxpvc-test/</span><br><span class="line"></span><br><span class="line">echo <span class="string">"&lt;h1&gt;Hello yichen~&lt;/h1&gt;"</span> &gt;&gt; /<span class="keyword">data</span>/k8s/nginxpvc-test/index.html</span><br></pre></td></tr></table></figure>

<p>这时候可以再去访问了。</p>
<p>查看在什么节点，然后可以进去容器看看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods  -o wide</span><br><span class="line"></span><br><span class="line">docker exec -it k8s_nginx_nfs-pvc-78d847877b-kxhh4_default_4266e &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure>



<h4 id="5-1-部署mysql持久化卷"><a href="#5-1-部署mysql持久化卷" class="headerlink" title="5.1.部署mysql持久化卷"></a>5.1.部署mysql持久化卷</h4><p><strong>部署mysql持久化卷</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql-pv-volume</span><br><span class="line">  labels:</span><br><span class="line">    type: local</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: manual</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  hostPath:</span><br><span class="line">    path: &quot;&#x2F;mnt&#x2F;data&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql-pv-claim</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: manual</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 2Gi</span><br></pre></td></tr></table></figure>

<p><strong>部署MySQL服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 3306</span><br><span class="line">  selector:</span><br><span class="line">    app: mysql</span><br><span class="line">  clusterIP: None</span><br><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1 # for versions before 1.9.0 use apps&#x2F;v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: mysql</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: mysql</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: mysql:5.7</span><br><span class="line">        name: mysql</span><br><span class="line">        env:</span><br><span class="line">        - name: MYSQL_ROOT_PASSWORD </span><br><span class="line">          value: password  # 改成自己实际的密码</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 3306</span><br><span class="line">          name: mysql</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: mysql-persistent-storage</span><br><span class="line">          mountPath: &#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">      volumes:</span><br><span class="line">      - name: mysql-persistent-storage</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: mysql-pv-claim</span><br></pre></td></tr></table></figure>

<p>创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f  mysql.yaml</span><br></pre></td></tr></table></figure>

<p>查看deployment mysql 资源详细信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe deployment mysql</span><br></pre></td></tr></table></figure>

<p>确认下服务是否按装完毕</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -l app&#x3D;mysql</span><br></pre></td></tr></table></figure>

<p>查看mysql-pv-claim 资源详细信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pvc mysql-pv-claim</span><br></pre></td></tr></table></figure>

<p>通过虚拟机宿主机登陆mysql镜像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run -it --rm --image&#x3D;mysql:5.6 --restart&#x3D;Never mysql-client -- mysql -h mysql -pLukeVip123</span><br></pre></td></tr></table></figure>

</div><ul class="post-copyright"><li><strong>本文标题：</strong><a href="https://yc6.cool/2020/08/04/k8s搭建/">kubernetes搭建</a></li><li><strong>本文作者：</strong><a href="https://yc6.cool">yichen</a></li><li><strong>本文链接：</strong><a href="https://yc6.cool/2020/08/04/k8s搭建/">https://yc6.cool/2020/08/04/k8s搭建/</a></li><li><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</span></li></ul><div><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/2023/05/17/Kubernetes%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/" target="_blank">Kubernetes高可用集群二进制部署</a><br></span><span>  2.<a class="is-size-6" href="/2022/03/12/openresty%E7%BB%93%E5%90%88lua%E5%AF%B9%E5%90%8C%E4%B8%80%E6%9D%A1%E5%9F%9F%E5%90%8D%E5%88%A4%E6%96%AD%E5%8F%82%E6%95%B0%E5%81%9A%E8%B4%9F%E8%BD%BD/" target="_blank">openresty结合lua对域名参数做负载均衡</a><br></span><span>  3.<a class="is-size-6" href="/2021/07/31/nginx%E5%88%A4%E6%96%AD%E5%BE%AE%E4%BF%A1%E7%AB%AF%E8%B7%B3%E8%BD%AC%E4%B8%8D%E5%90%8C%E9%A1%B5%E9%9D%A2/" target="_blank">nginx判断微信端跳转不同页面</a><br></span><span>  4.<a class="is-size-6" href="/2020/09/30/nftables/" target="_blank">nftables</a><br></span><span>  5.<a class="is-size-6" href="/2020/08/04/k8s%E4%B8%ADYAML%E6%96%87%E4%BB%B6%E7%BC%96%E5%86%99%E4%B8%8E%E4%BD%BF%E7%94%A8/" target="_blank">k8s中yaml文件编写与使用</a><br></span><span>  6.<a class="is-size-6" href="/2020/08/04/%E5%88%9B%E5%BB%BAcentos%E9%95%9C%E5%83%8F%E6%94%AF%E6%8C%81ssh/" target="_blank">创建centos镜像支持ssh远程连接</a><br></span><span>  7.<a class="is-size-6" href="/2020/08/04/docker%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E9%85%B7Q%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BAQQ%E6%9C%BA%E5%99%A8%E4%BA%BA/" target="_blank">docke一键安装酷Q搭建个人QQ机器人</a><br></span><span>  8.<a class="is-size-6" href="/2020/08/04/docker%E6%95%B0%E6%8D%AE%E5%8C%96%E6%8C%81%E4%B9%85%E5%8D%B7%E6%8F%92%E4%BB%B6/" target="_blank">docker数据持久卷插件</a><br></span></div><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 推荐文章</span><br><span>  1.<a class="is-size-6" href="/2020/08/04/docker%E4%BD%BF%E7%94%A8/" target="_blank">docker的使用</a><br></span><span>  2.<a class="is-size-6" href="/2020/08/03/mysql%E5%9F%BA%E7%A1%80/" target="_blank">mysql基础</a><br></span><span>  3.<a class="is-size-6" href="/2020/08/03/nginx%E5%9F%BA%E7%A1%80/" target="_blank">nginx基础</a><br></span><span>  4.<a class="is-size-6" href="/2020/08/04/python3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E9%87%8D%E7%82%B9/" target="_blank">python3基础知识重点</a><br></span><span>  5.<a class="is-size-6" href="/2023/05/07/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/" target="_blank">Prometheus监控linux</a><br></span><span>  6.<a class="is-size-6" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E9%82%AE%E7%AE%B1%E6%8E%A5%E6%94%B6%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/" target="_blank">Prometheus使用邮件接收告警通知</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://yichenxiu.com/tupian/tubiao/alipay1.jpg" alt="支付宝"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://i.328888.xyz/2023/03/05/dZXCk.jpeg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/08/04/k8s%E4%B8%ADYAML%E6%96%87%E4%BB%B6%E7%BC%96%E5%86%99%E4%B8%8E%E4%BD%BF%E7%94%A8/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">k8s中yaml文件编写与使用</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/08/04/%E5%88%9B%E5%BB%BAcentos%E9%95%9C%E5%83%8F%E6%94%AF%E6%8C%81ssh/"><span class="level-item">创建centos镜像支持ssh远程连接</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: '3f2c59f5d7e2a9b0575f30bfefb528db',
            repo: 'issue_database',
            owner: 'zhi666',
            clientID: '1b861f81e9a79ee6028d',
            clientSecret: 'cc629aff090aa9c60d5e13ddf7fcfce14f00a478',
            admin: ["zhi666"],
            createIssueManually: true,
            distractionFreeMode: true,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget toc-scroll" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list toc"><li><a class="is-flex toc-item" id="toc-item-k8s搭建" href="#k8s搭建"><span>k8s搭建</span></a><ul class="menu-list toc"><ul class="menu-list toc"><li><a class="is-flex toc-item" id="toc-item-一、系统规划" href="#一、系统规划"><span>一、系统规划</span></a></li><li><a class="is-flex toc-item" id="toc-item-二、初始化系统基础环境" href="#二、初始化系统基础环境"><span>二、初始化系统基础环境</span></a></li><li><a class="is-flex toc-item" id="toc-item-三-安装docker" href="#三-安装docker"><span>三.安装docker</span></a></li><li><a class="is-flex toc-item" id="toc-item-2-安装控制台仪表盘" href="#2-安装控制台仪表盘"><span>2.安装控制台仪表盘</span></a></li><li><a class="is-flex toc-item" id="toc-item-5-其它" href="#5-其它"><span>5. 其它</span></a></li></ul></ul></li><li><a class="is-flex toc-item" id="toc-item-部署管理k8s" href="#部署管理k8s"><span>部署管理k8s</span></a><ul class="menu-list toc"><ul class="menu-list toc"><li><a class="is-flex toc-item" id="toc-item-2-API部署例子" href="#2-API部署例子"><span>2.API部署例子</span></a></li><li><a class="is-flex toc-item" id="toc-item-二-k8s部署RC和RS应用" href="#二-k8s部署RC和RS应用"><span>二.k8s部署RC和RS应用</span></a></li><li><a class="is-flex toc-item" id="toc-item-3-1-网站服务应用" href="#3-1-网站服务应用"><span>3.1.网站服务应用</span></a></li><li><a class="is-flex toc-item" id="toc-item-PV" href="#PV"><span>PV</span></a></li><li><a class="is-flex toc-item" id="toc-item-5-1-部署mysql持久化卷" href="#5-1-部署mysql持久化卷"><span>5.1.部署mysql持久化卷</span></a></li></ul></ul></li></ul></div></div><script type="text/javascript" async>
        $(document).ready(function () { //参考自 https://github.com/ppoffice/hexo-theme-icarus/pull/616/files
            var observerTopMargin;
            var scrollObserver;
            var headerElems = $(".headerlink");
            var activeTocItem;
        
            function initIntersectionObserver(docHeight) {
                observerTopMargin = docHeight;
                scrollObserver = new IntersectionObserver(scrollCallBack,
                    {
                        root: null,  // viewpoint
                        rootMargin: docHeight + "px 0px -80% 0px"  // cover top 30% of viewport to the top of document
                    })
            }
        
            function scrollCallBack(entries, observer) {
                if ($(window).scrollTop() > observerTopMargin * 0.7) { 
                    // User somehow scroll to 70% of observerTopMargin (which is inited as 200% document height)
                    // Observer top margin need to extend to cover all the space to the top of the document
                    initIntersectionObserver(observerTopMargin * 2)
                    observer.disconnect();
                    return;
                }
                let toActive;
                if (entries[0].intersectionRatio == 1) {  // enter viewed area
                    let entry = entries.reduce((u, v) => (u.target.toc_id > v.target.toc_id ? u : v));  // get the lowest item
                    toActive = $("#toc-item-" + $(entry.target).attr("href").substr(1));
                } else {
                    let entry = entries.reduce((u, v) => (u.target.toc_id < v.target.toc_id ? u : v));  // get the highest item
                    let idx = Math.max(entry.target.toc_id - 1, 0);
                    toActive = $("#toc-item-" + $(headerElems[idx]).attr("href").substr(1));
                }
                if (activeTocItem) activeTocItem.removeClass("is-current");
                activeTocItem = toActive
                activeTocItem.addClass("is-current");
            }
        
            initIntersectionObserver($(document).height() * 2);
            headerElems.each(function (index, obj) {
                obj.toc_id = index;
                scrollObserver.observe(obj);
            })
        });</script></div><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/toudong.jpg" alt="逸尘秀"></figure><p class="title is-size-4 is-block line-height-inherit">逸尘秀</p><p class="is-size-6 is-block">只此一生 ， 必须快乐 ！</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>深圳</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">136</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">55</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://weibo.com/u/6155656382" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zhi666"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/6155656382"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:1378373724@qq.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Next" href="https://zhi666.github.io/remove.io"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"来源《"+data.from+"》</p><p>提供者-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2023-11-01T02:25:44.578Z">2023-11-01</time></p><p class="title is-6"><a class="link-muted" href="/2023/11/01/selenlium%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0dns%E5%9F%9F%E5%90%8D/">批量添加dns域名解析</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-17T01:45:36.000Z">2023-05-17</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/17/Kubernetes%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/">Kubernetes高可用集群二进制部署</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux3/">linux3</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-10T06:25:36.000Z">2023-05-10</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E6%89%8B%E6%9C%BA%E7%94%B5%E8%AF%9D_%E7%9F%AD%E4%BF%A1%E6%8E%A5%E6%94%B6%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/">Prometheus使用手机电话_短信接收告警通知</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux2/">linux2</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-10T06:22:36.000Z">2023-05-10</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%8E%A5%E6%94%B6%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/">Prometheus使用企业微信接收告警通知</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux2/">linux2</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-10T06:20:36.000Z">2023-05-10</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E4%BC%81%E4%B8%9A%E9%92%89%E9%92%89%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/">Prometheus使用企业钉钉接收告警通知</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux2/">linux2</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/English/"><span class="level-start"><span class="level-item">English</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/HTML/"><span class="level-start"><span class="level-item">HTML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/JS/"><span class="level-start"><span class="level-item">JS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/html/"><span class="level-start"><span class="level-item">html</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/linux1/"><span class="level-start"><span class="level-item">linux1</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/linux2/"><span class="level-start"><span class="level-item">linux2</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/linux3/"><span class="level-start"><span class="level-item">linux3</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/web/"><span class="level-start"><span class="level-item">web</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/work/"><span class="level-start"><span class="level-item">work</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">四月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag is-grey-lightest">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag is-grey-lightest">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prometheus/"><span class="tag">Prometheus</span><span class="tag is-grey-lightest">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/html/"><span class="tag">html</span><span class="tag is-grey-lightest">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nginx/"><span class="tag">nginx</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql/"><span class="tag">mysql</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%B9%E5%99%A8/"><span class="tag">容器</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"><span class="tag">科学上网</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/work/"><span class="tag">work</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"><span class="tag">自动化</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%9A%E5%AE%A2/"><span class="tag">博客</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E4%BD%9C/"><span class="tag">工作</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E5%85%B7/"><span class="tag">工具</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ssl/"><span class="tag">ssl</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"><span class="tag">文件系统</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%BF%97/"><span class="tag">日志</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%BF%97%E5%8A%A0%E5%AF%86/"><span class="tag">日志加密</span><span class="tag is-grey-lightest">3</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=zhi666FeedsId&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="zhi666FeedsId" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div><p class="help">输入邮箱开始订阅，更博后邮件通知！</p></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="逸尘秀" height="28"></a><p class="size-small"><span>&copy; 2023 yichen</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>,Modify by <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">removeif</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2020/08/02 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zhi666"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://yc6.cool',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back-to-top.js" defer></script><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.12/js/lightgallery-all.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><!--!--><!--!--><!--!--><script src="/js/toc.js" defer></script><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('1b861f81e9a79ee6028d','cc629aff090aa9c60d5e13ddf7fcfce14f00a478','zhi666','issue_database',false);})</script><link rel="stylesheet" href="/css/insight.css"><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="想要查找什么..."><span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>(function (window) {
            var INSIGHT_CONFIG = {
                TRANSLATION: {
                    POSTS: '文章',
                    PAGES: '页面',
                    CATEGORIES: '分类',
                    TAGS: '标签',
                    UNTITLED: '(无标题)',
                },
                CONTENT_URL: '/content.json',
            };
            window.INSIGHT_CONFIG = INSIGHT_CONFIG;
        })(window);</script><script src="/js/insight.js" defer></script></body></html>