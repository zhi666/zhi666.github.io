<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><meta name="keywords" content="[object Object]"><meta name="description" content="1,urllib爬取网页和写入文件"><meta name="author" content="zhi666"><title>python3爬虫 - 逸尘秀</title><meta description="1,urllib爬取网页和写入文件"><meta property="og:type" content="article"><meta property="og:title" content="python3爬虫"><meta property="og:url" content="https://yc6.cool/2020/08/04/%E7%88%AC%E8%99%AB/"><meta property="og:site_name" content="逸尘秀"><meta property="og:description" content="1,urllib爬取网页和写入文件"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2020-08-04T04:02:36.000Z"><meta property="article:modified_time" content="2023-11-01T02:25:44.589Z"><meta property="article:author" content="zhi666"><meta property="article:tag" content="python"><meta property="article:tag" content="爬虫"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://yc6.cool/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://yc6.cool/2020/08/04/%E7%88%AC%E8%99%AB/"},"headline":"python3爬虫","image":["https://yc6.cool/img/avatar.png"],"datePublished":"2020-08-04T04:02:36.000Z","dateModified":"2023-11-01T02:25:44.589Z","author":{"@type":"Person","name":"zhi666"},"description":"1,urllib爬取网页和写入文件"}</script><link rel="alternative" href="/atom.xml" title="逸尘秀" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.12/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><link rel="stylesheet" href="/css/style.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><link rel="stylesheet" href="/live2d/waifu.css"><script type="text/javascript" async src="/live2d/autoload.js"></script></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="逸尘秀" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/media">影音</a><a class="navbar-item" href="/album">相册</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/self-talking">碎碎念</a><a class="navbar-item" href="/message">留言</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zhi666"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2020-08-04  <a class="commentCountImg" href="/2020/08/04/%E7%88%AC%E8%99%AB/#comment-container"><span class="display-none-class">50b0e5af7862320ca92b4c942a6e36ac</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="50b0e5af7862320ca92b4c942a6e36ac">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>12 分钟  <i class="fas fa-pencil-alt"> </i>1.8 k</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">python3爬虫</h1><div class="content"><h1 id="1-urllib爬取网页和写入文件"><a href="#1-urllib爬取网页和写入文件" class="headerlink" title="1,urllib爬取网页和写入文件"></a>1,urllib爬取网页和写入文件</h1><a id="more"></a>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">#encoding&#x3D;&quot;utf-8&quot;</span><br><span class="line"># 向指定的url地址发起请求，并返回服务器响应的数据(文件的对象)</span><br><span class="line">response &#x3D; urllib.request.urlopen(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)</span><br><span class="line"> # 获取数据， decode(&quot;utf-8&quot;) 表示转为字符串utf-8编码</span><br><span class="line">#data &#x3D;response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">#读取文件的全部内容</span><br><span class="line">#data &#x3D;response.read()</span><br><span class="line">#print(data)</span><br><span class="line">#print(type(data))</span><br><span class="line"></span><br><span class="line">#将爬取到的网页写入文件，会把读取到的数据赋值给一个字符串变量</span><br><span class="line">#with open(r&quot;D:\py_work\grep\爬虫\file\file1.html&quot; ,&quot;wb&quot;) as f:</span><br><span class="line">#    f.write(data)</span><br><span class="line"></span><br><span class="line">#response 属性</span><br><span class="line">#返回当前环境的有关信息</span><br><span class="line">print(response.info())</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">#返回状态码</span><br><span class="line">print(response.getcode())</span><br><span class="line">if response.getcode() &#x3D;&#x3D; 200 or response.getcode() &#x3D;&#x3D; 304:</span><br><span class="line">     #处理网页信息</span><br><span class="line">     pass</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">#返回当前正在爬取的url地址</span><br><span class="line">print(response.geturl())</span><br><span class="line"></span><br><span class="line">url &#x3D; &quot;https:&#x2F;&#x2F;www.baidu.com&#x2F;s?wd&#x3D;%E9%95%BF%E5%9F%8E&amp;rsv_spt&#x3D;1&amp;rsv_iqid&#x3D;0xe262cf6300014620&amp;issp&#x3D;1&amp;f&#x3D;8&amp;rsv_bp&#x3D;1&amp;rsv_idx&#x3D;2&amp;ie&#x3D;utf-8&amp;tn&#x3D;baiduhome_pg&amp;rsv_enter&#x3D;1&amp;rsv_dl&#x3D;tb&amp;rsv_sug2&#x3D;0&amp;rsv_btype&#x3D;i&amp;inputT&#x3D;4262&amp;rsv_sug4&#x3D;6162&quot;</span><br><span class="line">#读取一行</span><br><span class="line">#data &#x3D; response.readline()</span><br><span class="line"></span><br><span class="line">#读取文件的全部内容，会把读取的数据赋值给一个列表变量</span><br><span class="line">data &#x3D;response.readlines()</span><br><span class="line">print(data)</span><br><span class="line">print(type(data))</span><br><span class="line">print(len(data))</span><br><span class="line">print(type(data[100].decode(&quot;utf-8&quot;)))</span><br></pre></td></tr></table></figure>

<h1 id="2-模拟浏览器"><a href="#2-模拟浏览器" class="headerlink" title="2, 模拟浏览器"></a>2, 模拟浏览器</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import random</span><br><span class="line">url &#x3D; &quot;http:&#x2F;&#x2F;www.baidu.com&quot;</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">#模拟请求头</span><br><span class="line">header &#x3D;&#123;</span><br><span class="line">    &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Linux; Android 8.0; Pixel 2 Build&#x2F;OPD3.170816.012) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;81.0.4044.138 Mobile Safari&#x2F;537.36&quot;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#完整的heater</span><br><span class="line">header &#x3D;&#123;</span><br><span class="line">    &quot;Accept&quot;:&quot;text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;webp,image&#x2F;apng,*&#x2F;*;q&#x3D;0.8,application&#x2F;signed-exchange;v&#x3D;b3;q&#x3D;0.9&quot;,</span><br><span class="line">    &quot;X-Requested-With&quot;: &quot;XMLHttpRequest&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Linux; Android 8.0; Pixel 2 Build&#x2F;OPD3.170816.012) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;81.0.4044.138 Mobile Safari&#x2F;537.36&quot;,</span><br><span class="line">    &quot;Content-Type&quot;: &quot;text&#x2F;html;charset&#x3D;utf-8&quot;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">#设置一个请求体</span><br><span class="line">req &#x3D; urllib.request.Request(url,headers&#x3D;header)</span><br><span class="line"></span><br><span class="line">#发起请求</span><br><span class="line"></span><br><span class="line">response &#x3D; urllib.request.urlopen(req)</span><br><span class="line">data&#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line"></span><br><span class="line">print(data)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">#user-agent大全</span><br><span class="line">agentsList &#x3D; [</span><br><span class="line">    &quot;Mozilla&#x2F;5.0 (Windows NT 6.1; WOW64) AppleWebKit&#x2F;535.1 (KHTML, like Gecko) Chrome&#x2F;14.0.835.163 Safari&#x2F;535.1&quot;,</span><br><span class="line">    &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;73.0.3683.103 Safari&#x2F;537.36&quot;,</span><br><span class="line">    &quot;Mozilla&#x2F;4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident&#x2F;4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0)&quot;,</span><br><span class="line">    &quot;User-Agent: Mozilla&#x2F;4.0 (compatible; MSIE 7.0; Windows NT 5.1; TencentTraveler 4.0)&quot;,</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line">#随机拿出user-agent</span><br><span class="line">agentStr &#x3D; random.choice(agentsList)</span><br><span class="line"></span><br><span class="line">req &#x3D;urllib.request.Request(url)</span><br><span class="line">#向请求体添加了User-Agent</span><br><span class="line">req.add_header(&quot;User-Agent&quot;,agentStr)</span><br><span class="line"></span><br><span class="line">response &#x3D;urllib.request.urlopen(req)</span><br><span class="line"></span><br><span class="line">data &#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure>

<h1 id="3-设置超时"><a href="#3-设置超时" class="headerlink" title="3,设置超时"></a>3,设置超时</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#如果网页长时间未响应，系统判断超时，无法爬取</span><br><span class="line"></span><br><span class="line">for i in range(1,100):</span><br><span class="line">    try:</span><br><span class="line">        response &#x3D; urllib.request.urlopen(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;, timeout&#x3D;0.5)</span><br><span class="line">        print(len(response.read().decode(&quot;utf-8&quot;)))</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;请求超时，继续下一个爬取&quot;)</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>

<h1 id="4-http请求"><a href="#4-http请求" class="headerlink" title="4,http请求"></a>4,http请求</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">使用场景: 进行客户端与服务端之间的消息传递时使用</span><br><span class="line"></span><br><span class="line">GET:        通过URL网址传递信息，可以直接在URL网址上添加要传递的信息</span><br><span class="line">POST:       可以向服务器提交数据，是一种比较流行的比较安全的数据传递方式</span><br><span class="line">PUT:        请求服务器存储一个资源，通常要指定存储的位置</span><br><span class="line">DELETE:     请求服务器删除一个资源</span><br><span class="line">HEAD:       请求获取对应的http报头信息</span><br><span class="line">OPTIONS:    可以获取当前URL所支持的请求类型</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure>

<h2 id="1-get请求"><a href="#1-get请求" class="headerlink" title="1,get请求"></a>1,get请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#GET请求</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">特点：把数据拼接到请求路径的后面传递给服务器</span><br><span class="line">优点： 速度快</span><br><span class="line">缺点： 承载的数据量少，不安全</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">import urllib.request</span><br><span class="line"></span><br><span class="line">url &#x3D;&quot;https:&#x2F;&#x2F;yichenxiu.com&#x2F;html&#x2F;wenzi&#x2F;&quot;</span><br><span class="line"></span><br><span class="line">response &#x3D; urllib.request.urlopen(url)</span><br><span class="line"></span><br><span class="line">data &#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">print(data)</span><br><span class="line">print(type(data))</span><br></pre></td></tr></table></figure>

<h2 id="2-json数据解析"><a href="#2-json数据解析" class="headerlink" title="2,json数据解析"></a>2,json数据解析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&#39;&#39;&#39;</span><br><span class="line">概念：一种保存数据的格式</span><br><span class="line">作用：可以保存本地的json文件，也可以将json串进行传输，通常将json称为轻量级的传输方式。</span><br><span class="line"></span><br><span class="line">json文件的组成</span><br><span class="line">&#123;&#125;          代表对象(字典)</span><br><span class="line">[]          代表列表</span><br><span class="line">:           代表键值对</span><br><span class="line">,           分隔两个部分</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">jsonStr &#x3D; &#39;&#39;&#39;&#123;&quot;name&quot;:&quot;yichen秀&quot;,&quot;age&quot;:18,</span><br><span class="line">&quot;hobby&quot;:[&quot;money&quot;,&quot;power&quot;,&quot;english&quot;],&quot;parames&quot;:&#123;&quot;a&quot;:1,&quot;b&quot;:2&#125;&#125;&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">#将json格式的字符串转为python数据类型的对象</span><br><span class="line">jsonData &#x3D; json.loads(jsonStr)</span><br><span class="line">print(jsonData)</span><br><span class="line">print(type(jsonData))</span><br><span class="line">print(jsonData[&quot;hobby&quot;])</span><br><span class="line"></span><br><span class="line">#将python格式的字符串转为json数据类型的对象</span><br><span class="line">jsonData2 &#x3D; &#39;&#39;&#39;&#123;&quot;name&quot;:&quot;yichen秀&quot;,&quot;age&quot;:18,</span><br><span class="line">&quot;hobby&quot;:[&quot;money&quot;,&quot;power&quot;,&quot;english&quot;],&quot;parames&quot;:&#123;&quot;a&quot;:1,&quot;b&quot;:2&#125;&#125;&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">jsonStr2 &#x3D; json.dumps(jsonData2)</span><br><span class="line">print(jsonStr2)</span><br><span class="line">print(type(jsonStr2))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#读取本地的json文件</span><br><span class="line">path1 &#x3D; r&quot;D:\py_work\grep\爬虫\file\config.json&quot;</span><br><span class="line"></span><br><span class="line">with open(path1,&quot;rb&quot;) as f:</span><br><span class="line">    data &#x3D; json.load(f)</span><br><span class="line">    print(data)</span><br><span class="line">    #字典类型</span><br><span class="line">    print(type(data))</span><br><span class="line">#写本地的json文件</span><br><span class="line"></span><br><span class="line">path2 &#x3D; r&quot;D:\py_work\grep\爬虫\file\config.json&quot;</span><br><span class="line">jsonData3 &#x3D; &#39;&#39;&#39;&#123;&quot;name&quot;:&quot;yichen秀&quot;,&quot;age&quot;:18,</span><br><span class="line">&quot;hobby&quot;:[&quot;money&quot;,&quot;power&quot;,&quot;english&quot;],&quot;parames&quot;:&#123;&quot;a&quot;:1,&quot;b&quot;:2&#125;&#125;&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">with open(path2, &quot;w&quot;) as f :</span><br><span class="line">    json.dump(jsonData3,f)</span><br></pre></td></tr></table></figure>

<h2 id="3-POST请求"><a href="#3-POST请求" class="headerlink" title="3, POST请求"></a>3, POST请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">#POST请求</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">特点: 把参数进行打包，单独传输</span><br><span class="line"></span><br><span class="line">优点:数量大，安全(当对服务器数据进行修改时建议使用post)</span><br><span class="line"></span><br><span class="line">缺点: 速度慢</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line"></span><br><span class="line">url &#x3D;&quot;https:&#x2F;&#x2F;yichenxiu.com&#x2F;look&#x2F;login.php?referer&#x3D;https%3A%2F%2Fyichenxiu.com%2Flook%2Fwelcome.php&quot;</span><br><span class="line">#将要发送的数据合成一个字典</span><br><span class="line">#字典的键去网址里找，一般为input标签的name属性的值</span><br><span class="line">data &#x3D; &#123;</span><br><span class="line">    &quot;name&quot;:&quot;yichen&quot;,</span><br><span class="line">    &quot;password&quot;:&quot;****!&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#对要发送的数据进行打包</span><br><span class="line">postData &#x3D; urllib.parse.urlencode(data).encode(&quot;utf-8&quot;)</span><br><span class="line"></span><br><span class="line">header &#x3D; &#123;</span><br><span class="line">    &quot;Accept&quot;:&quot;text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;webp,image&#x2F;apng,*&#x2F;*;q&#x3D;0.8,application&#x2F;signed-exchange;v&#x3D;b3;q&#x3D;0.9&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;81.0.4044.138 Safari&#x2F;537.36&quot;,</span><br><span class="line">    &quot;Content-Type&quot;:&quot;application&#x2F;x-www-form-urlencoded&quot;,</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#请求体</span><br><span class="line">req &#x3D;urllib.request.Request(url, data&#x3D;postData,headers&#x3D;header)</span><br><span class="line"></span><br><span class="line">#req.add_header(&quot;User-Agent&quot;, &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;81.0.4044.138 Safari&#x2F;537.36&quot;)</span><br><span class="line">#请求</span><br><span class="line">response &#x3D; urllib.request.urlopen(req)</span><br><span class="line"></span><br><span class="line">data1 &#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line"></span><br><span class="line">print(data1)</span><br><span class="line">#把文件保存</span><br><span class="line">with open(r&quot;D:\py_work\grep\爬虫\file\file2.html&quot; ,&quot;w&quot;,encoding&#x3D;&quot;utf-8&quot;) as f:</span><br><span class="line">    f.write(data1)</span><br></pre></td></tr></table></figure>



<h1 id="5，抓取网页动态Ajax请求的数据"><a href="#5，抓取网页动态Ajax请求的数据" class="headerlink" title="5，抓取网页动态Ajax请求的数据"></a>5，抓取网页动态Ajax请求的数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import ssl</span><br><span class="line">import json,time</span><br><span class="line"></span><br><span class="line">def ajaxCrawler(url):</span><br><span class="line"></span><br><span class="line">    headers &#x3D;&#123;</span><br><span class="line">    &quot;User-Agent&quot;:&quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;83.0.4103.61 Safari&#x2F;537.36&quot;,</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    req &#x3D; urllib.request.Request(url,headers &#x3D; headers)</span><br><span class="line">    context &#x3D; ssl._create_unverified_context()</span><br><span class="line">    #使用ssl创建未验证的上下文</span><br><span class="line">    response &#x3D; urllib.request.urlopen(req,context&#x3D;context)</span><br><span class="line"></span><br><span class="line">    jsonStr &#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">    jsonData &#x3D; json.loads(jsonStr)</span><br><span class="line"></span><br><span class="line">    return jsonData</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">url&#x3D; &quot;https:&#x2F;&#x2F;movie.douban.com&#x2F;j&#x2F;chart&#x2F;top_list?type&#x3D;17&amp;interval_id&#x3D;100%3A90&amp;action&#x3D;&amp;start&#x3D;40&amp;limit&#x3D;20&quot;</span><br><span class="line">info &#x3D; ajaxCrawler(url)</span><br><span class="line">print(info)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">for i in range(1,11):</span><br><span class="line">    url &#x3D;&quot;https:&#x2F;&#x2F;movie.douban.com&#x2F;j&#x2F;chart&#x2F;top_list?type&#x3D;17&amp;interval_id&#x3D;100%3A90&amp;action&#x3D;&amp;start&#x3D;&quot;+ str(i*20)+&quot;&amp;limit&#x3D;20&quot;</span><br><span class="line">    info &#x3D; ajaxCrawler(url)</span><br><span class="line">    print(len(info))</span><br><span class="line"></span><br><span class="line">    #print(info)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    with open(r&quot;D:\py_work\grep\爬虫\file\file3.html&quot;, &quot;a&quot;,encoding&#x3D;&quot;utf-8&quot; ) as f:</span><br><span class="line">        f.write(str(info))</span><br></pre></td></tr></table></figure>

<h1 id="6-糗事百科爬虫"><a href="#6-糗事百科爬虫" class="headerlink" title="6,糗事百科爬虫"></a>6,糗事百科爬虫</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import re</span><br><span class="line">def jokeCrawler(url):</span><br><span class="line">    headers &#x3D;&#123;</span><br><span class="line">        &quot;User-Agent&quot;:&quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;83.0.4103.61 Safari&#x2F;537.36&quot;,</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    req &#x3D; urllib.request.Request(url,headers &#x3D; headers)</span><br><span class="line"></span><br><span class="line">    response &#x3D; urllib.request.urlopen(req)</span><br><span class="line">    Html &#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">    #Html &#x3D; str(response.read())</span><br><span class="line">    #print(Html)</span><br><span class="line">    #正则匹配</span><br><span class="line">    pat &#x3D;r&#39;&lt;div class&#x3D;&quot;author clearfix&quot;&gt;(.*?)&lt;span class&#x3D;&quot;stats-vote&quot;&gt;&lt;i class&#x3D;&quot;number&quot;&gt;&#39;</span><br><span class="line"></span><br><span class="line">    divsList &#x3D; re.findall(pat,Html,re.S)</span><br><span class="line">    #print(divsList)</span><br><span class="line">    #print(len(divsList))</span><br><span class="line">    dic &#x3D; &#123;&#125;</span><br><span class="line">    for div in divsList:</span><br><span class="line">        #用户名</span><br><span class="line">        re_u &#x3D; re.compile(r&quot;&lt;h2&gt;(.*?)&lt;&#x2F;h2&gt;&quot;,re.S)</span><br><span class="line">        username &#x3D;re_u.findall(div)</span><br><span class="line">        #print(username[0])</span><br><span class="line">        username &#x3D; username[0]</span><br><span class="line">        #print(type(username))</span><br><span class="line"></span><br><span class="line">        #段子</span><br><span class="line">        re_d &#x3D; re.compile(r&#39;&lt;div class&#x3D;&quot;content&quot;&gt;\n&lt;span&gt;(.*?)&lt;&#x2F;span&gt;&#39;, re.S)</span><br><span class="line">        duanzi &#x3D; re_d.findall(div)</span><br><span class="line">        #print(duanzi[0])</span><br><span class="line">        dic[username] &#x3D; duanzi</span><br><span class="line"></span><br><span class="line">    return dic</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url &#x3D; r&quot;https:&#x2F;&#x2F;www.qiushibaike.com&#x2F;text&#x2F;page&#x2F;2&#x2F;&quot;</span><br><span class="line">info &#x3D; jokeCrawler(url)</span><br><span class="line"></span><br><span class="line">print(info)</span><br><span class="line">for k,v in info.items():</span><br><span class="line">    print(k + &quot;说\n&quot;,v)</span><br><span class="line"></span><br><span class="line">with open(r&quot;D:\py_work\grep\爬虫\file\file5.html&quot;, &quot;w&quot;, encoding&#x3D;&quot;utf-8&quot;) as f:</span><br><span class="line">    f.write(str(info))</span><br></pre></td></tr></table></figure>

<h1 id="7-爬图片练习"><a href="#7-爬图片练习" class="headerlink" title="7,爬图片练习"></a>7,爬图片练习</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request,re,os</span><br><span class="line">def imageCrawler(url,toPath):</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line">        &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;83.0.4103.61 Safari&#x2F;537.36&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    req &#x3D; urllib.request.Request(url, headers&#x3D;headers)</span><br><span class="line">    response &#x3D; urllib.request.urlopen(req)</span><br><span class="line">    HtmlStr &#x3D; response.read().decode(&quot;utf-8&quot;)</span><br><span class="line">    # with open(r&quot;D:\py_work\grep\爬虫\file\image\yhd.html&quot;, &quot;wb&quot;) as f:</span><br><span class="line">    #   f.write(HtmlStr)</span><br><span class="line"></span><br><span class="line">    pat &#x3D; r&#39;&lt;img src&#x3D;(.*?) alt&#x3D;&quot;&quot;&#39;</span><br><span class="line">    re_image &#x3D; re.compile(pat)</span><br><span class="line">    imageList &#x3D; re_image.findall(HtmlStr)</span><br><span class="line">    print(imageList)</span><br><span class="line">    print(len(imageList))</span><br><span class="line">    num &#x3D; 1</span><br><span class="line">    for imageUrl in imageList:</span><br><span class="line">        path &#x3D; os.path.join(toPath, str(num)+&quot;.jpg&quot;)</span><br><span class="line">        num +&#x3D; 1</span><br><span class="line">        # 把图片下载到本地存储</span><br><span class="line">        urllib.request.urlretrieve(&quot;http:&#x2F;&#x2F;&quot;+imageUrl,filename&#x3D;path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url &#x3D; r&quot;https:&#x2F;&#x2F;qianggou.yhd.com&#x2F;ajax&#x2F;ajaxActivityProduct.do?pageNo&#x3D;1&amp;siteType&#x3D;&amp;provinceId&#x3D;2&amp;grouponId&#x3D;558169034&amp;_&#x3D;1590000642329&quot;</span><br><span class="line">toPath &#x3D; r&quot;D:\py_work\grep\爬虫\file\image&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imageCrawler(url,toPath)</span><br></pre></td></tr></table></figure>

<h1 id="8，爬取网络中的QQ号"><a href="#8，爬取网络中的QQ号" class="headerlink" title="8，爬取网络中的QQ号"></a>8，爬取网络中的QQ号</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">import urllib.request</span><br><span class="line">import ssl</span><br><span class="line">import os</span><br><span class="line">import re</span><br><span class="line">from collections import deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def writeFileByte(htmlBytes,toPath):</span><br><span class="line">    with open(toPath,&quot;wb&quot;) as f:</span><br><span class="line">        f.write(htmlBytes)</span><br><span class="line">def writeFileStr(htmlBytes,toPath):</span><br><span class="line">    with open(toPath,&quot;w&quot;) as f:</span><br><span class="line">        f.write(str(htmlBytes))</span><br><span class="line"></span><br><span class="line">def getHtmlBytes(url):</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line"></span><br><span class="line">        &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;83.0.4103.61 Safari&#x2F;537.36&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    # 请求头</span><br><span class="line">    req &#x3D; urllib.request.Request(url, headers&#x3D;headers)</span><br><span class="line">    context&#x3D;ssl._create_unverified_context()</span><br><span class="line">    # 请求体</span><br><span class="line">    response &#x3D; urllib.request.urlopen(req,context&#x3D;context)</span><br><span class="line"></span><br><span class="line">    return response.read()</span><br><span class="line"></span><br><span class="line">#爬取网页信息+文件存储目录文件</span><br><span class="line">def qqCrawler(url,toPath):</span><br><span class="line">    htmlBytes&#x3D;getHtmlBytes(url)</span><br><span class="line">    writeFileByte(htmlBytes,r&quot;D:\py_work\grep\爬虫\file\image\file1.html&quot;)</span><br><span class="line">    writeFileStr(htmlBytes,r&quot;D:\py_work\grep\爬虫\file\image\file2.txt&quot;)</span><br><span class="line">    htmlStr&#x3D;str(htmlBytes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#找qq号</span><br><span class="line">    #pat&#x3D;r&#39;&lt;&#x2F;li&gt;\n&lt;li class&#x3D;&quot;d_name&quot; data-field&#x3D;(.*?)&#125;&#39;</span><br><span class="line">    pat&#x3D;r&quot;[1-9]\d&#123;4,9&#125;&quot;</span><br><span class="line">    re_qq&#x3D;re.compile(pat)</span><br><span class="line"></span><br><span class="line">    qqList&#x3D;re_qq.findall(htmlStr)</span><br><span class="line">    #去重复</span><br><span class="line">    qqList&#x3D;list(set(qqList))</span><br><span class="line"></span><br><span class="line">    f&#x3D;open(toPath,&quot;a&quot;)</span><br><span class="line">    for qqStr in qqList:</span><br><span class="line">        f.write(qqStr+&quot;\n&quot;)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #找网址</span><br><span class="line">    pat1&#x3D;r&#39;(((http|ftp|https?):&#x2F;&#x2F;)(([a-zA-Z0-9\._-]+\.[a-zA-Z]&#123;2,6&#125;)|([0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;))(:[0-9]&#123;1,4&#125;)*(&#x2F;[a-zA-Z0-9\&amp;%_\.&#x2F;-~-]*)?)&#39;</span><br><span class="line">    re_url&#x3D;re.compile(pat1)</span><br><span class="line">    urlsList&#x3D;re_url.findall(htmlStr)</span><br><span class="line">    #去重</span><br><span class="line">    urlsList&#x3D;list(set(urlsList))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    return urlsList</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def center(url,toPath):</span><br><span class="line">    queue&#x3D;deque()</span><br><span class="line"></span><br><span class="line">    queue.append(url)</span><br><span class="line"></span><br><span class="line">    while len(queue)!&#x3D;0:</span><br><span class="line">        targetUrl&#x3D;queue.popleft()</span><br><span class="line">        urlList&#x3D;qqCrawler(targetUrl,toPath)</span><br><span class="line">        for item in urlList:</span><br><span class="line">            tempUrl&#x3D;item[0]</span><br><span class="line">            queue.append(tempUrl)</span><br><span class="line"></span><br><span class="line">#爬取地址</span><br><span class="line">url &#x3D;&quot;https:&#x2F;&#x2F;tieba.baidu.com&#x2F;p&#x2F;2&quot;</span><br><span class="line"></span><br><span class="line">#QQ存储目录文件</span><br><span class="line">toPath &#x3D; r&quot;D:\py_work\grep\爬虫\file\image\qqFile.txt&quot;</span><br><span class="line">center(url,toPath)</span><br></pre></td></tr></table></figure>

</div><ul class="post-copyright"><li><strong>本文标题：</strong><a href="https://yc6.cool/2020/08/04/爬虫/">python3爬虫</a></li><li><strong>本文作者：</strong><a href="https://yc6.cool">yichen</a></li><li><strong>本文链接：</strong><a href="https://yc6.cool/2020/08/04/爬虫/">https://yc6.cool/2020/08/04/爬虫/</a></li><li><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</span></li></ul><div><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/2023/11/01/selenlium%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0dns%E5%9F%9F%E5%90%8D/" target="_blank">批量添加dns域名解析</a><br></span><span>  2.<a class="is-size-6" href="/2023/11/01/python%E4%B9%8BSelenium%E6%A8%A1%E5%9D%97/" target="_blank">python之Selenium模块的使用</a><br></span><span>  3.<a class="is-size-6" href="/2021/07/23/%E5%88%A9%E7%94%A8python%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E6%8B%86%E5%88%86/" target="_blank">利用Python实现文件拆分</a><br></span><span>  4.<a class="is-size-6" href="/2020/08/04/python%E4%B9%8BDjango/" target="_blank">python3之Django</a><br></span><span>  5.<a class="is-size-6" href="/2020/08/04/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B/" target="_blank">python3多任务进程线程</a><br></span><span>  6.<a class="is-size-6" href="/2020/08/04/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" target="_blank">python3网络编程</a><br></span><span>  7.<a class="is-size-6" href="/2020/08/04/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" target="_blank">python3正则表达式</a><br></span><span>  8.<a class="is-size-6" href="/2020/08/04/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%8E%B7%E5%8F%96%E5%90%84%E7%A7%8D%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9/" target="_blank">python3自动化获取各种文件内容</a><br></span></div><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 推荐文章</span><br><span>  1.<a class="is-size-6" href="/2020/08/04/docker%E4%BD%BF%E7%94%A8/" target="_blank">docker的使用</a><br></span><span>  2.<a class="is-size-6" href="/2020/08/03/mysql%E5%9F%BA%E7%A1%80/" target="_blank">mysql基础</a><br></span><span>  3.<a class="is-size-6" href="/2020/08/03/nginx%E5%9F%BA%E7%A1%80/" target="_blank">nginx基础</a><br></span><span>  4.<a class="is-size-6" href="/2020/08/04/python3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E9%87%8D%E7%82%B9/" target="_blank">python3基础知识重点</a><br></span><span>  5.<a class="is-size-6" href="/2023/05/07/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/" target="_blank">Prometheus监控linux</a><br></span><span>  6.<a class="is-size-6" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E9%82%AE%E7%AE%B1%E6%8E%A5%E6%94%B6%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/" target="_blank">Prometheus使用邮件接收告警通知</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://yichenxiu.com/tupian/tubiao/alipay1.jpg" alt="支付宝"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://i.328888.xyz/2023/03/05/dZXCk.jpeg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/08/04/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">python3网络编程</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/08/04/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"><span class="level-item">python3正则表达式</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.0/gitalk.css"><script> $.getScript('/js/gitalk.min.js', function () { 
            var gitalk = new Gitalk({
            language:'zh-CN',
            id: '50b0e5af7862320ca92b4c942a6e36ac',
            repo: 'issue_database',
            owner: 'zhi666',
            clientID: '1b861f81e9a79ee6028d',
            clientSecret: 'cc629aff090aa9c60d5e13ddf7fcfce14f00a478',
            admin: ["zhi666"],
            createIssueManually: true,
            distractionFreeMode: true,
            perPage: 10,
            pagerDirection: 'last',
            proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token',
            
            enableHotKey: true,
            isLocked: false
        })
        gitalk.render('comment-container')});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget toc-scroll" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list toc"><li><a class="is-flex toc-item" id="toc-item-1-urllib爬取网页和写入文件" href="#1-urllib爬取网页和写入文件"><span>1,urllib爬取网页和写入文件</span></a></li><li><a class="is-flex toc-item" id="toc-item-2-模拟浏览器" href="#2-模拟浏览器"><span>2, 模拟浏览器</span></a></li><li><a class="is-flex toc-item" id="toc-item-3-设置超时" href="#3-设置超时"><span>3,设置超时</span></a></li><li><a class="is-flex toc-item" id="toc-item-4-http请求" href="#4-http请求"><span>4,http请求</span></a><ul class="menu-list toc"><li><a class="is-flex toc-item" id="toc-item-1-get请求" href="#1-get请求"><span>1,get请求</span></a></li><li><a class="is-flex toc-item" id="toc-item-2-json数据解析" href="#2-json数据解析"><span>2,json数据解析</span></a></li><li><a class="is-flex toc-item" id="toc-item-3-POST请求" href="#3-POST请求"><span>3, POST请求</span></a></li></ul></li><li><a class="is-flex toc-item" id="toc-item-5，抓取网页动态Ajax请求的数据" href="#5，抓取网页动态Ajax请求的数据"><span>5，抓取网页动态Ajax请求的数据</span></a></li><li><a class="is-flex toc-item" id="toc-item-6-糗事百科爬虫" href="#6-糗事百科爬虫"><span>6,糗事百科爬虫</span></a></li><li><a class="is-flex toc-item" id="toc-item-7-爬图片练习" href="#7-爬图片练习"><span>7,爬图片练习</span></a></li><li><a class="is-flex toc-item" id="toc-item-8，爬取网络中的QQ号" href="#8，爬取网络中的QQ号"><span>8，爬取网络中的QQ号</span></a></li></ul></div></div><script type="text/javascript" async>
        $(document).ready(function () { //参考自 https://github.com/ppoffice/hexo-theme-icarus/pull/616/files
            var observerTopMargin;
            var scrollObserver;
            var headerElems = $(".headerlink");
            var activeTocItem;
        
            function initIntersectionObserver(docHeight) {
                observerTopMargin = docHeight;
                scrollObserver = new IntersectionObserver(scrollCallBack,
                    {
                        root: null,  // viewpoint
                        rootMargin: docHeight + "px 0px -80% 0px"  // cover top 30% of viewport to the top of document
                    })
            }
        
            function scrollCallBack(entries, observer) {
                if ($(window).scrollTop() > observerTopMargin * 0.7) { 
                    // User somehow scroll to 70% of observerTopMargin (which is inited as 200% document height)
                    // Observer top margin need to extend to cover all the space to the top of the document
                    initIntersectionObserver(observerTopMargin * 2)
                    observer.disconnect();
                    return;
                }
                let toActive;
                if (entries[0].intersectionRatio == 1) {  // enter viewed area
                    let entry = entries.reduce((u, v) => (u.target.toc_id > v.target.toc_id ? u : v));  // get the lowest item
                    toActive = $("#toc-item-" + $(entry.target).attr("href").substr(1));
                } else {
                    let entry = entries.reduce((u, v) => (u.target.toc_id < v.target.toc_id ? u : v));  // get the highest item
                    let idx = Math.max(entry.target.toc_id - 1, 0);
                    toActive = $("#toc-item-" + $(headerElems[idx]).attr("href").substr(1));
                }
                if (activeTocItem) activeTocItem.removeClass("is-current");
                activeTocItem = toActive
                activeTocItem.addClass("is-current");
            }
        
            initIntersectionObserver($(document).height() * 2);
            headerElems.each(function (index, obj) {
                obj.toc_id = index;
                scrollObserver.observe(obj);
            })
        });</script></div><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/toudong.jpg" alt="逸尘秀"></figure><p class="title is-size-4 is-block line-height-inherit">逸尘秀</p><p class="is-size-6 is-block">只此一生 ， 必须快乐 ！</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>深圳</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">136</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">55</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://weibo.com/u/6155656382" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zhi666"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/6155656382"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:1378373724@qq.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="Next" href="https://zhi666.github.io/remove.io"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-white is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"来源《"+data.from+"》</p><p>提供者-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2023-11-01T02:25:44.578Z">2023-11-01</time></p><p class="title is-6"><a class="link-muted" href="/2023/11/01/selenlium%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0dns%E5%9F%9F%E5%90%8D/">批量添加dns域名解析</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/python/">python</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-17T01:45:36.000Z">2023-05-17</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/17/Kubernetes%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2/">Kubernetes高可用集群二进制部署</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux3/">linux3</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-10T06:25:36.000Z">2023-05-10</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E6%89%8B%E6%9C%BA%E7%94%B5%E8%AF%9D_%E7%9F%AD%E4%BF%A1%E6%8E%A5%E6%94%B6%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/">Prometheus使用手机电话_短信接收告警通知</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux2/">linux2</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-10T06:22:36.000Z">2023-05-10</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%8E%A5%E6%94%B6%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/">Prometheus使用企业微信接收告警通知</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux2/">linux2</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2023-05-10T06:20:36.000Z">2023-05-10</time></p><p class="title is-6"><a class="link-muted" href="/2023/05/10/Prometheus%E4%BD%BF%E7%94%A8%E4%BC%81%E4%B8%9A%E9%92%89%E9%92%89%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5/">Prometheus使用企业钉钉接收告警通知</a></p><p class="is-uppercase"><i class="fas fa-folder-open has-text-grey"> </i><a class="link-muted" href="/categories/linux2/">linux2</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/English/"><span class="level-start"><span class="level-item">English</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/HTML/"><span class="level-start"><span class="level-item">HTML</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/JS/"><span class="level-start"><span class="level-item">JS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/html/"><span class="level-start"><span class="level-item">html</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/linux1/"><span class="level-start"><span class="level-item">linux1</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/linux2/"><span class="level-start"><span class="level-item">linux2</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/linux3/"><span class="level-start"><span class="level-item">linux3</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/web/"><span class="level-start"><span class="level-item">web</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/work/"><span class="level-start"><span class="level-item">work</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><a class="level is-mobile is-marginless" href="/categories/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/04/"><span class="level-start"><span class="level-item">四月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><a class="level is-mobile is-marginless" href="/archives/"><span class="level-start"><span class="level-item">查看全部&gt;&gt;</span></span></a></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag is-grey-lightest">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag is-grey-lightest">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prometheus/"><span class="tag">Prometheus</span><span class="tag is-grey-lightest">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/html/"><span class="tag">html</span><span class="tag is-grey-lightest">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nginx/"><span class="tag">nginx</span><span class="tag is-grey-lightest">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql/"><span class="tag">mysql</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%B9%E5%99%A8/"><span class="tag">容器</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"><span class="tag">科学上网</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/work/"><span class="tag">work</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"><span class="tag">自动化</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%9A%E5%AE%A2/"><span class="tag">博客</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E4%BD%9C/"><span class="tag">工作</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E5%85%B7/"><span class="tag">工具</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ssl/"><span class="tag">ssl</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"><span class="tag">文件系统</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%BF%97/"><span class="tag">日志</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%BF%97%E5%8A%A0%E5%AF%86/"><span class="tag">日志加密</span><span class="tag is-grey-lightest">3</span></a></div></div><div class="field is-grouped is-grouped-multiline"><a class="tags has-addons" href="/tags/"><span class="tag">查看全部&gt;&gt;</span></a></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=zhi666FeedsId&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="zhi666FeedsId" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div><p class="help">输入邮箱开始订阅，更博后邮件通知！</p></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="逸尘秀" height="28"></a><p class="size-small"><span>&copy; 2023 yichen</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>,Modify by <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">removeif</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2020/08/02 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zhi666"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://yc6.cool',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back-to-top.js" defer></script><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.12/js/lightgallery-all.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><!--!--><!--!--><!--!--><script src="/js/toc.js" defer></script><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('1b861f81e9a79ee6028d','cc629aff090aa9c60d5e13ddf7fcfce14f00a478','zhi666','issue_database',false);})</script><link rel="stylesheet" href="/css/insight.css"><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="想要查找什么..."><span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>(function (window) {
            var INSIGHT_CONFIG = {
                TRANSLATION: {
                    POSTS: '文章',
                    PAGES: '页面',
                    CATEGORIES: '分类',
                    TAGS: '标签',
                    UNTITLED: '(无标题)',
                },
                CONTENT_URL: '/content.json',
            };
            window.INSIGHT_CONFIG = INSIGHT_CONFIG;
        })(window);</script><script src="/js/insight.js" defer></script></body></html>